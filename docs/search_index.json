[
["index.html", "Training Manual for SDAL Welcome", " Training Manual for SDAL Welcome The purpose of this website is to consolodate all of the ‘basic’ trainings and knowledge in the lab to be used as a reference and trainining handbook used in our summer Data Science for the Public Good Program. "],
["the-social-and-decision-analytics-laboratory.html", "The Social and Decision Analytics Laboratory", " The Social and Decision Analytics Laboratory The Social and Decision Analytics Laboratory brings together statisticians and social and behavioral scientists to embrace today’s data revolution, developing evidence-based research and quantitative methods to inform policy decision-making. https://www.bi.vt.edu/sdal/about Overview: Our Mission &amp; Methods As a leading laboratory in the Biocomplexity Institute of Virginia Tech, the Social and Decision Analytics Laboratory is modeling the social condition of metropolitan areas, integrating novel sources of data to examine health and wellness, and uncovering key factors that drive industrial innovation. Social and decision analytics have the power to fundamentally change our understanding of the world around us. Our research informs effective policy-making under uncertainty, combining expertise in statistics and the social sciences to transform all data into actionable knowledge. Leveraging analytics to solve real-world problems requires a broad range of expertise. The SDAL team includes thought leaders in a wide variety of fields: statistics, social, behavioral and economic sciences, political science, psychology, simulation, computer science, data analytics, information technology policy, and infrastructural resilience. SDAL is driven to make data analytics an accessible and effective part of the policy-making process. SDAL’s newest partnerships and recent discoveries are regularly profiled on our news page, while public lectures are available in our presentations archive. Our location at the Virginia Tech Research Center in Arlington, Virginia allows us to partner with local, state, and federal governments, non-profit organizations, and industry throughout the D.C. metro area and beyond. Innovation: Our Research Focus Areas Every global challenge we face today is rooted in information. Advances in big data analysis have the potential to revolutionize the ways we address long-standing social problems such as unequal access to services and affordable housing. To address these and other pressing issues, the Social and Decision Analytics Laboratory is pioneering three major domains of research. The Science of “All” Data aims to integrate disparate sources of data—surveys and experiments; local, state, and federal administrative government records; social media; mobile technology, and geographic information—to deliver a comprehensive understanding of social problems. We are experts in drawing actionable information out of messy data sets of all sizes. Information Diffusion Analytics charts how knowledge and social attitudes spread through information networks using a combination of network science, cognitive modeling, crowd-sourcing, and machine learning. Our research predicts how information reaches people and affects their outlook. Community Learning Data-Driven Discovery (CLD3) allows organizations to identify individually maintained data resources that serve their mutual needs. Information that would have been siloed within a single department is “liberated,” freed for use throughout the community. Our research focuses on how to discovery, liberate, and repurpose these data flows to achieve data-informed policy development. Our unique CLD3 approach is supported by expertise in five sub-domains of analytics research: Metropolitan Analytics applies data on infrastructure, environment, and people to understand how urban areas can support the well-being of their expanding populations. Our research guides the growth of resilient cities. Education and Labor Force Analytics seeks to provide a clearer picture of the factors that help students and employees thrive by understanding learning processes, social interactions, and learning environments. Our work examines the impact of education on labor force outcomes. Health and Well Being Analytics leverages public and private sector medical data to help communities deliver healthcare services where they are most needed. SDAL studies help healthcare resources do more good. Emergency Management Analytics creates deep characterizations of situational awareness at all levels through accessing and integrating comprehensive information of conditions that increase risks and stress to the emergency responders and the citizens they serve. Our research guides the development of equitable policies and practices to improve the safety and security of our communities. Industrial Innovation Analytics utilizes data from partners in the private sector to identify factors that reduce costs and improve efficiency. We enable the private sector to move beyond business analytics to develop information integration technologies. Collaboration: Our Research Partnerships Since its founding in 2013, SDAL has developed its world-class statistical and data science capabilities in support of the Biocomplexity Institute’s overarching mission to predict, explain, and visualize the behavior of massively interacting systems. Backed by the Biocomplexity Institute’s diverse research programs and unique, high-performance computing infrastructure, SDAL has established long-term partnerships with a variety of organizations including Arlington County, Procter &amp; Gamble, the Robert Wood Johnson Foundation, the United States Census Bureau, and the Department of Housing and Urban Development. The Social and Decision Analytics Laboratory welcomes new collaboration opportunities. To inquire, please contact our director, Sallie Keller. "],
["data-science-for-the-public-good-program.html", "Data Science for the Public Good Program", " Data Science for the Public Good Program The Data Science for the Public Good program (DSPG) engages young scholars in finding solutions to some of the most pressing social issues of our time. DSPG fellows conduct research at the intersection of statistics, computation, and the social sciences to determine how information generated within every community can be leveraged to improve quality of life. Problem Our communities are engaged in a tremendous struggle to manage conflicting forces that threaten their ability to evolve and thrive. Government officials and policymakers must continuously develop their capacity to provide health, safety, security, employment, and leisure to their constituents. Sustaining this level of growth is becoming increasingly difficult in a climate of diminishing resources, mounting inequality, rapid technological change, and expanding global networks. Data-driven research provides a rich, mutually rewarding opportunity to leverage community knowledge and public information resources to affect positive social change. The Data Science for the Public Good program was established to connect aspiring data science scholars to communities which can benefit from their expertise. Students selected through a competitive application process are engaged in a series of hands-on learning experiences while policymakers and government leaders receive data analysis support to inform difficult decisions related to healthcare, education, and social justice. The story of each community—its problems, needs, and aspirations—is contained within its data. The DSPG program’s overarching objective is to equip new generations of scientists with the skills they need to bring this story to light for leaders in local government. Methods The Data Science for the Public Good program teaches student fellows how to sift through vast amounts of information related to public safety, employment, and the provision of services to discover how communities can become more efficient and sustainable. Through the lenses of statistics, social science, and data science research, DSPG students will learn to integrate all available data resources in order to: Identify pressing issues through direct engagement with government and community leaders. Develop mechanisms to assist decision-makers in framing their large-scale policy questions and identifying data sources which can be leveraged to address these issues at the local, state, and federal levels. Create a two-way data pipeline to give local leaders a direct link to cutting-edge scientific analyses and researchers easier access to local, state, and federal data flows. DSPG fellows are also given opportunities to diversify their expertise and form lasting professional connections by taking part in the Social and Decision Analytics Laboratory’s data-driven research projects. Our research teams are: Horizontally integrated, combining disciplines including statistics, data science, and the social and behavioral sciences to address complex issues. Vertically integrated, allowing students to collaborate with project stakeholders at all levels including undergraduates, graduates, postdoctoral associates, research faculty, and local, state, and federal agency leadership. These unique fellowship experiences are made possible through the support of several research organizations dedicated to serving the public good: Virginia Tech’s Global Forum for Urban and Regional Resilience (GFURR); American Statistical Association’s NSF Research Experience for Undergraduates (REU); and sponsored research. Impact As metropolitan areas assume greater responsibility for driving social transformation and economic prosperity, the demand for publicly engaged and highly trained data scientists will continue to grow. For students eager to participate in this emerging field, the Data Science for Public Good program promises to deliver a unique set of resources and opportunities. World-Class Training: DSPG fellows participate in professional training and development workshops, poster presentations, and technical report and publication writing. Formal sessions on data science practices introduce students to scientific and statistical computing tools including R, Python, and GIS. Workshops also include accessing and using local, state and federal data resources such as Census products and open data portals. Professional Support: Each DSPG fellow is assigned a post-doctoral and senior researcher mentor. These mentors guide students’ research and facilitate discussions about future career opportunities, with a focus on public service. DSPG fellows also participate in strategic planning activities related to their projects including sponsor meetings, presentations, and other events. National Networks: Leveraging our laboratory’s location in the National Capital Region, excursions are organized to events at AAAS, national academies, congressional hearings, and a variety of Washington metropolitan science and technology activities. Fellows also attend the SDAL seminar series with national and international speakers from government, academia, and industry. To learn more about how our DSPG program is making a difference in the lives of students, read this profile on our inaugural cohort of summer research fellows. Program Sponsors: Who We Work With Every DSPG research project begins with a collaboration. While our sponsor organizations face unique challenges, they share a common commitment: leveraging data science to better serve the public good. Figure .: Nonexclusive list of sponsors Previous Projects Data Science for the Public Good Research Presentations Research from the Data Science for the Public Good (DSPG) program addresses fundamental problems faced by governmental agencies tasked with serving the public good, institutions ranging from the Department of Defense to emergency response services in our local county. The poster presentations below represent the range of research we’ve performed on behalf of each of our sponsors. You can find a list of previous presentations here: https://www.bi.vt.edu/sdal/careers/call-for-students/dspg-research-presentations "],
["lesson-materials.html", "Lesson Materials", " Lesson Materials The main source for the training materials come from Software-Carpentry (Wilson 2016), specifically the Bash, Git (Ahmadia et al. 2016), and SQL lessons. More references about Software-Carpentry and the challenges in scientific computing can be found here: (Wilson, n.d.) (Wilson 2009) (Hannay et al. 2009) (Wilson 2008) (Wilson 2006) (Wilson 2005) Software-Carpenty Data-Carpentry The Carpentries DataCamp R for Data Science By: Garrett Grolemund and Hadley Wickham http://r4ds.had.co.nz/ Figure .: R for Data Science Cover References "],
["setup.html", "Setup", " Setup In general, the only thing you really need to work on our servers is a browser. However, having a terminal application (e.g., Bash Shell) is really useful. The setup instructions are taken and adapted from the Software-Carpenty Workshop Template "],
["the-bash-shell.html", "The Bash Shell", " The Bash Shell Bash is a commonly-used shell that gives you the power to do simple tasks more quickly. Windows Video Tutorial Download the Git for Windows installer: https://git-for-windows.github.io/. Run the installer and follow the steps bellow: Click on “Next”. Click on “Next”. Keep “Use Git from the Windows Command Prompt” selected and click on “Next”. If you forgot to do this programs that you need for the workshop will not work properly. If this happens rerun the installer and select the appropriate option. Click on “Next”. Keep “Checkout Windows-style, commit Unix-style line endings” selected and click on “Next”. Keep “Use Windows’ default console window” selected and click on “Next”. Click on “Install”. Click on “Finish”. If your “HOME” environment variable is not set (or you don’t know what this is): Open command prompt (Open Start Menu then type cmd and press [Enter]) Type the following line into the command prompt window exactly as shown: setx HOME &quot;%USERPROFILE%&quot; Press [Enter], you should see SUCCESS: Specified value was saved. Quit command prompt by typing exit then pressing [Enter] This will provide you with both Git and Bash in the Git Bash program. macOS The default shell in all versions of macOS is Bash, so no need to install anything. You access Bash from the Terminal (found in /Applications/Utilities). See the Git installation video tutorial for an example on how to open the Terminal. You may want to keep Terminal in your dock for this workshop. Linux The default shell is usually Bash, but if your machine is set up differently you can run it by opening a terminal and typing bash. There is no need to install anything. "],
["git.html", "Git", " Git Git is a version control system that lets you track who made changes to what when and has options for easily updating a shared or public version of your code on github.com. You will need a supported web browser (current versions of Chrome, Firefox or Safari, or Internet Explorer version 9 or above). You will need an account at github.com for parts of the Git lesson. Basic GitHub accounts are free. We encourage you to create a GitHub account if you don’t have one already. Please consider what personal information you’d like to reveal. For example, you may want to review these instructions for keeping your email address private provided at GitHub. Windows Git should be installed on your computer as part of your Bash install (described above). macOS Video Tutorial For OS X 10.9 and higher, install Git for Mac by downloading and running the most recent “mavericks” installer from this list. After installing Git, there will not be anything in your /Applications folder, as Git is a command line program. For older versions of OS X (10.5-10.8) use the most recent available installer labelled “snow-leopard” available here. Linux If Git is not already available on your machine you can try to install it via your distro’s package manager. For Debian/Ubuntu run sudo apt-get install git and for Fedora run sudo dnf install git. "],
["text-editor.html", "Text Editor", " Text Editor When you’re writing code, it’s nice to have a text editor that is optimized for writing code, with features like automatic color-coding of key words. The default text editor on macOS and Linux is usually set to Vim, which is not famous for being intuitive. If you accidentally find yourself stuck in it, try typing the escape key, followed by :q! (colon, lower-case ‘q’, exclamation mark), then hitting Return to return to the shell. Atom: https://flight-manual.atom.io/getting-started/sections/installing-atom/ Sublime Text: https://www.sublimetext.com/3 Emacs VIM Windows Video Tutorial nano is a basic editor and the default that instructors use in the workshop. To install it, download the Windows installer and double click on the file to run it. This installer requires an active internet connection. Others editors that you can use are Notepad++ or Sublime Text. Be aware that you must add its installation directory to your system path. Please ask your instructor to help you do this. macOS nano is a basic editor and the default that instructors use in the workshop. See the Git installation video tutorial for an example on how to open nano. It should be pre-installed. Others editors that you can use are Text Wrangler or Sublime Text. Linux nano is a basic editor and the default that instructors use in the workshop. It should be pre-installed. Others editors that you can use are Gedit, Kate or Sublime Text. "],
["r.html", "R", " R R is a programming language that is especially powerful for data exploration, visualization, and statistical analysis. To interact with R, we use RStudio. RStudio IDE: https://www.rstudio.com/products/rstudio/download/preview/ Windows Video Tutorial Install R by downloading and running this .exe file from CRAN. Also, please install the RStudio IDE. Note that if you have separate user and admin accounts, you should run the installers as administrator (right-click on .exe file and select “Run as administrator” instead of double-clicking). Otherwise problems may occur later, for example when installing R packages. macOS Video Tutorial Install R by downloading and running this .pkg file from CRAN. Also, please install the RStudio IDE. Linux You can download the binary files for your distribution from CRAN. Or you can use your package manager (e.g. for Debian/Ubuntu run sudo apt-get install r-base and for Fedora run sudo dnf install R). Also, please install the RStudio IDE. Post installation settings Open up global options You can do this by going to Tools &gt; Global Options on the top menu bar. Setup startup defaults Make sure: “Restore .RData into workspace at startup” box is unchecked “Save workspace to .RData on exit” is set to “Never” It’s also advised to uncheck the top two options as well: Restore most recently opened project at startup Restore previously open source documents at startup "],
["sqlite.html", "SQLite", " SQLite SQL is a specialized programming language used with databases. We use a simple database manager called SQLite in our lessons. Windows The Windows Installer installs SQLite for Windows. If you used the installer to configure nano, you don’t need to run it again. macOS SQLite comes pre-installed on macOS. Linux SQLite comes pre-installed on Linux. "],
["ssh-keys.html", "SSH Keys", " SSH Keys Typically we’ll be going over this step together as a class. As long as you have Bash installed you’ll be okay. It’ll be a good idea to first check and see if you already have any SSH keys: https://help.github.com/articles/checking-for-existing-ssh-keys/ GitHub has a set of instructions on how to create SSH keys: https://help.github.com/articles/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent/#generating-a-new-ssh-key The below is an adapted form of the GiHub instructions Open Terminal. run ssh-keygen, this creates a new ssh key Generating public/private rsa key pair. When you’re prompted to “Enter a file in which to save the key,” press Enter. This accepts the default file location. Enter a file in which to save the key (/home/you/.ssh/id_rsa): [Press enter] At the prompt, when it asks for a password, just leave it blank and [Press enter]. Otherwise, for more information, see “Working with SSH key passphrases”. Enter passphrase (empty for no passphrase): [Type a passphrase] Enter same passphrase again: [Type passphrase again] If you look at the contents of ~/.ssh, you should see the id_rsa and id_rsa.pub files. $ ls ~/.ssh id_rsa id_rsa.pub Copy the public key (is_rsa.pub) $ cat ~/.ssh/id_rsa.pub This is the public key you will use to paste into the system that asks for an SSH key Other resources: https://www.rosehosting.com/blog/ssh-login-without-password-using-ssh-keys/ GitHub Once you have your ssh key copied, you can add the key to your GitHub account by following the GitHub instructions: https://help.github.com/articles/adding-a-new-ssh-key-to-your-github-account/ Lightfoot If you have an SSH key on your laptop, you can use it so you don’t have to type your password when logging into lightfoot run ssh-copy-id $ ssh-copy-id YOUR_PID@lightfoot.vbi.vt.edu It will prompt you for your password, and if it’s your first time connecting to the server also ask you to confirm the connection by typing yes Once you ran ssh-copy-id, you can connect directly to lightfoot $ ssh YOUR_PID@lightfoot.vbi.vt.edu GitLab (devlab) The process of adding a key to GitLab is similar to the GitHub instuctions: https://docs.gitlab.com/ee/gitlab-basics/create-your-ssh-keys.html "],
["latex.html", "LaTeX", " LaTeX Please go to https://www.latex-project.org/get/ to find the LaTeX distribution for your operating system. If you can, you should try to install the “full” version of TeX, but it is a very large install. The upside of installing everything is usually you’ll never have a problem in the future with loading TeX or LaTeX packages. There’s also a very good LaTeX IDE called TeXstudio: https://www.texstudio.org/. It’s a fork of Texmaker (http://www.xm1math.net/texmaker/), but I find that TeXstudio has better autocompletes. You can try both of them, they’re pretty much the same (in both function and visuals) "],
["syllabus.html", "Syllabus", " Syllabus The bulk of the material comes from the R for Data Science by Hadley Wickham and Garrett Grolemund. There are additional topics that come from Software-Carpentry, and various other materials found online. Supplemental material comes from an appropriate DataCamp course. Each chapter (and sometimes a set of chapters) can be taught within a 3 hour block with a break roughly every 45 minutes. The total amount of material cover’s roughly a months worth of material (3 Hours a day, 5 Days a week). The introduction page for each chapter contains links to relevent chapters and additional resources. "],
["lesson-breakdown.html", "Lesson Breakdown", " Lesson Breakdown Lesson 1 Goals: Get up and running in the lab Know what bits of infrastructure we have Introduction to R through visualization How to load your own data into R Getting setup Getting the shell SSH keys The SDAL Infrastructure RStudio The other tools availiable Shell (Bash) The “Tidyverse” ecosystem Scripts and running R code Exploring your data through visualizations (ggplot2) Loading and saving a datasets (readr, haven) Lesson 2 Goals: Introduction to Markdown (rmarkdown) and knitr Take “pretty” notes with “simple” notation Learn how to create basic reports with your code What the code projects look like Working with git locally Markdown Knitr The project template Workflow basics Projects Git (locally) Lesson 3 Goals: Git with an eye towards collaboration Working with remotes (GitHub and GitLab) Collaborating with branches Git (remotes) Git (branches) Git (collaboration) Lesson 4 Goals: Start the process of manipulating data Perform data subsetting and aggregations Explore data with basic statistics and visualizations Reshaping data and fixing common data problems through the tidying process Transform data with (dplyr) Pipes (%&gt;%) Exploratory Data Analysis (EDA) tibble, the tidyverse “dataframe” Tidying data (tidyr) Lesson 5 Goals: Understanding relational data Merging datasets together Work with relational data in a database Writing SQL code and how to run them from within R Relational Data in R (dplyr) Working with databases SQLite PostgreSQL SQL Working with SQL in your R code Lesson 6 Goals: Work with strings, factors, and date time values in R Strings Factors (forcats) Dates and Times Lesson 7 Programming “fundamentals” Functions Vectors Loops Functions Vectors Iteration purrr for loops Lesson 8 Goals: The dialects of R Review of tidyverse functions How tidyverse relates to base R The base R data.frame object apply family of functions How data.table playes a role in the R ecosystem base R data.table tidyverse Lesson 9 Working with geospatial data with sf Lesson 10 Goals: Web scraping API Scrape Lesson 11 Communication R Markdown Graphics R Markdown formats Shiny "],
["infrastructure.html", "Chapter 1 Infrastructure", " Chapter 1 Infrastructure We have 2 servers in the lab, lightfoot and snowmane (named after horses from Lord of the Rings). The main “production” server is lightfoot where all of our data and compute resources exist. "],
["components.html", "1.1 Components", " 1.1 Components We use Docker in our lab. This allows us to install various components without affecting the underlying server. A brief history of how we settled on docker and why is in this blog post on From VMs to LXC Containers to Docker Containers. Figure 1.1 depicts what conatiners we have on lightfoot. You can think of each ‘container’ as an ‘application’ just like one you are running on your laptop. But the behvaior of each ‘container’ is more like a separate server you connect to. Figure 1.1: The Docker infrastructure used in SDAL. The containers on the top row are the parts of the system lab members will be connecting to and working on. The primary conatiners you will be using are the RStudio, Adminer, and Django/Wagtail containers. They all exist on lightfoot and can all be reached in a browser with https://analytics.bi.vt.edu and an appropriate suffix (e.g., /rstudio, /db). "],
["accessing-servers.html", "1.2 Accessing Servers", " 1.2 Accessing Servers Your main point of contact will be using RStudio on lightfoot. There’s a few things that can be setup so you don’t have to type your password all the time. This involves creating “SSH keys”. Aside from creating keys, below is a set of links you’ll probably be using all the time: Rstudio Your own container: https://analytics.bi.vt.edu/YOUR_PID/rstudio It’s suggested you use the container assigned to yourself, since your work and crashed code is isolated from everyone else Generic RStudio container: https://analytics.bi.vt.edu/rstudio There is a generic container that can be used as well, it’s availiable to you, but if you have an individual conatiner, it’s better to use that one instead "],
["project-template.html", "1.3 Project Template", " 1.3 Project Template Why project templates: https://chendaniely.github.io/sdal/2017/05/30/project_templates/ Other resources: https://github.com/ropensci/rrrpkg https://github.com/benmarwick/rrtools A template for research projects structured as R packages: https://github.com/Pakillo/template project/ # the project/code repository | |- data/ # raw and primary data, are not changed once created | | | +- project_data/ # subfolder that links to an encrypted data storage container | | | | | |- original/ # raw data, will not be altered | | |- working/ # intermediate datasets from src code | | +- final/ # datasets used in analysis | | | +- more_data/ # some projects will need multiple links | |- src/ # any programmatic code | |- analysis1/ # user1 assigned to the project | +- analysis2/ # user2 assigned to the project | |- R/ # functions | |- tests/ # unit tests | |- output # all output and results from workflows and analyses | |- figures/ # graphs, likely designated for manuscript figures | |- pictures/ # diagrams, images, and other non-graph graphics | +- analysis/ # generated reports for (e.g. rmarkdown output) | |- README.md # the top level description of content | |- .gitignore # git ignore file |- project.Rproj # RStudio project | |- DESCRIPTION # Description file to repo into R package, if applicable +- Makefile # Makefile, if applicable Notes: you can find our project template .gitignore file here: https://github.com/bi-sdal/project_template/blob/master/gitignore "],
["getting-a-project-repository.html", "1.4 Getting a project repository", " 1.4 Getting a project repository All of our code exist on a GitLab server (https://devlab.vbi.vt.edu) 1.4.1 Using Terminal You can use the SSH or HTTPS link (selected blue text) to run git clone to pull down the repository code. In general this should be cloned into the git folder in your home folder. cd ~ git clone &lt;REPO URL HERE&gt; 1.4.2 Using RStudio The steps in RStudio actually do the same thing as the steps from the terminal. Find the repository you plan to work on. Get the SSH url. You can also use the HTTPS url if you have not setup your SSH keys. File &gt; New Project Version Control Git Enter repository URL Paste in the repository URL from earlier. The “Project data name” should auto fill itself with the name of the repository (selected in blue text). It’s highly advised to put the project into a folder designated for repositories (e.g., git, Repositories). You can make sure the project get’s cloned to the correct place in the “Create project as a subdirectory of” section of the page. The loaded project RStudio will git clone the repository to the designated folder and open the project. The top right corner will tell you which project you are in. Make sure you check this everytime you start working. "],
["data-visualization.html", "Chapter 2 Data Visualization", " Chapter 2 Data Visualization Data visualization Chapter in r4ds http://r4ds.had.co.nz/data-visualisation.html Datacamp Courses: The ggplot2 stack https://www.datacamp.com/courses/data-visualization-with-ggplot2-1 https://www.datacamp.com/courses/data-visualization-with-ggplot2-2 https://www.datacamp.com/courses/data-visualization-with-ggplot2-part-3 "],
["loading-ggplot2.html", "2.1 Loading ggplot2", " 2.1 Loading ggplot2 library(ggplot2) # mpg dataset from the ggplot2 library mpg ## # A tibble: 234 x 11 ## manufacturer model displ year cyl trans drv cty hwy fl ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; ## 1 audi a4 1.8 1999 4 auto(l… f 18 29 p ## 2 audi a4 1.8 1999 4 manual… f 21 29 p ## 3 audi a4 2 2008 4 manual… f 20 31 p ## 4 audi a4 2 2008 4 auto(a… f 21 30 p ## 5 audi a4 2.8 1999 6 auto(l… f 16 26 p ## 6 audi a4 2.8 1999 6 manual… f 18 26 p ## 7 audi a4 3.1 2008 6 auto(a… f 18 27 p ## 8 audi a4 quat… 1.8 1999 4 manual… 4 18 26 p ## 9 audi a4 quat… 1.8 1999 4 auto(l… 4 16 25 p ## 10 audi a4 quat… 2 2008 4 manual… 4 20 28 p ## # ... with 224 more rows, and 1 more variable: class &lt;chr&gt; "],
["creating-a-ggplot.html", "2.2 Creating a ggplot", " 2.2 Creating a ggplot ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) "],
["aesthetic-mapings.html", "2.3 Aesthetic Mapings", " 2.3 Aesthetic Mapings # using color ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, color = class)) # using size ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, size = class)) ## Warning: Using size for a discrete variable is not advised. # using alpha ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, alpha = class)) # using shape ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy, shape = class)) ## Warning: The shape palette can deal with a maximum of 6 discrete values ## because more than 6 becomes difficult to discriminate; you have 7. ## Consider specifying shapes manually if you must have them. ## Warning: Removed 62 rows containing missing values (geom_point). # manual set property # note color is not in the aes ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy), color = &quot;blue&quot;) # if you put a variable outside you will get an error ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy), color = class) "],
["facets.html", "2.4 Facets", " 2.4 Facets ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + facet_wrap(~ class, nrow = 2) ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + facet_grid(drv ~ cyl) "],
["geometic-objects.html", "2.5 Geometic Objects", " 2.5 Geometic Objects ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) ggplot(data = mpg) + geom_smooth(mapping = aes(x = displ, y = hwy)) ## `geom_smooth()` using method = &#39;loess&#39; ggplot(data = mpg) + geom_smooth(mapping = aes(x = displ, y = hwy, linetime = drv)) ## Warning: Ignoring unknown aesthetics: linetime ## `geom_smooth()` using method = &#39;loess&#39; # base plot before groupings ggplot(data = mpg) + geom_smooth(mapping = aes(x = displ, y = hwy)) ## `geom_smooth()` using method = &#39;loess&#39; # base plot before groupings ggplot(data = mpg) + geom_smooth(mapping = aes(x = displ, y = hwy)) ## `geom_smooth()` using method = &#39;loess&#39; # separate smoothing line by group ggplot(data = mpg) + geom_smooth(mapping = aes(x = displ, y = hwy, group = drv)) ## `geom_smooth()` using method = &#39;loess&#39; # different color foe each group ggplot(data = mpg) + geom_smooth(mapping = aes(x = displ, y = hwy, color = drv), show.legend = FALSE) ## `geom_smooth()` using method = &#39;loess&#39; Adding multiple geoms in the same plot ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) + geom_smooth(mapping = aes(x = displ, y = hwy)) ## `geom_smooth()` using method = &#39;loess&#39; The layering system will carry over values from the previous layer. the ggplot layer will specify the global values ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + geom_point() + geom_smooth() ## `geom_smooth()` using method = &#39;loess&#39; Mappings in a a geom function, will overwrite the global settings (i.e., they are local settings) ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + geom_point(mapping = aes(color = class)) + geom_smooth() ## `geom_smooth()` using method = &#39;loess&#39; ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + geom_point(mapping = aes(color = class)) + geom_smooth( data = dplyr::filter(mpg, class == &#39;subcompact&#39;), se = FALSE ) ## `geom_smooth()` using method = &#39;loess&#39; "],
["statistical-transformations.html", "2.6 Statistical Transformations", " 2.6 Statistical Transformations dim(diamonds) ## [1] 53940 10 head(diamonds) ## # A tibble: 6 x 10 ## carat cut color clarity depth table price x y z ## &lt;dbl&gt; &lt;ord&gt; &lt;ord&gt; &lt;ord&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.23 Ideal E SI2 61.5 55 326 3.95 3.98 2.43 ## 2 0.21 Premium E SI1 59.8 61 326 3.89 3.84 2.31 ## 3 0.23 Good E VS1 56.9 65 327 4.05 4.07 2.31 ## 4 0.290 Premium I VS2 62.4 58 334 4.2 4.23 2.63 ## 5 0.31 Good J SI2 63.3 58 335 4.34 4.35 2.75 ## 6 0.24 Very Good J VVS2 62.8 57 336 3.94 3.96 2.48 ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut)) Use a stat to calculate a new value. diamonds data gets “transformed” into a frequency table that get’s plotted by the bar plot. Look at the geom_bar documentation, you will see the stat will be count (i.e., stat_count()). ggplot(data = diamonds) + stat_count(mapping = aes(x = cut)) You can set stat to ‘identity’ if you have already calculated a frequency table pre_counted &lt;- tibble::as.tibble(table(diamonds$cut)) ggplot(data = pre_counted) + geom_bar( mapping = aes(x = Var1, y = n), stat = &#39;identity&#39; ) # overwrite default stat # proportion instead of count ggplot(data = diamonds) + geom_bar( mapping = aes(x = cut, y = ..prop.., group = 1) ) grouping: http://ggplot2.tidyverse.org/reference/aes_group_order.html By default, the group is set to the interaction of all discrete variables in the plot. This often partitions the data correctly, but when it does not, or when no discrete variable is used in the plot, you will need to explicitly define the grouping structure, by mapping group to a variable that has a different value for each group. "],
["position-adjustments.html", "2.7 Position Adjustments", " 2.7 Position Adjustments # using color ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, color = cut)) # using fill ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, fill = cut)) # another example of fill # fill a different variable than x # This creates a stacked bar chart ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, fill = clarity)) position: identity ggplot(data = diamonds, mapping = aes(x = cut, fill = clarity)) + geom_bar(alpha = 1/5, position = &#39;identity&#39;) ggplot(data = diamonds, mapping = aes(x = cut, color = clarity)) + geom_bar(fill = NA, position = &#39;identity&#39;) potition: fill ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, fill = clarity), position = &#39;fill&#39;) position: dodge ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, fill = clarity), position = &#39;dodge&#39;) Jitter scatter plot ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy)) ggplot(data = mpg) + geom_point(mapping = aes(x = displ, y = hwy), position = &#39;jitter&#39;) "],
["coordinate-systems.html", "2.8 Coordinate Systems", " 2.8 Coordinate Systems coord_flipswaps the x and y axis, useful when you have long labels ggplot(data = mpg, mapping = aes(x = class, y = hwy)) + geom_boxplot() ggplot(data = mpg, mapping = aes(x = class, y = hwy)) + geom_boxplot() + coord_flip() coord_quickmap, sets aspect ratio for maps usa &lt;- ggplot2::map_data(&#39;usa&#39;) ggplot(usa, aes(long, lat, group = group)) + geom_polygon(fill = &#39;white&#39;, color = &#39;black&#39;) ggplot(usa, aes(long, lat, group = group)) + geom_polygon(fill = &#39;white&#39;, color = &#39;black&#39;) + coord_quickmap() corrd_polar, uses polar coordinates bar &lt;- ggplot(data = diamonds) + geom_bar(mapping = aes(x = cut, fill = cut), show.legend = FALSE, width = 1) + theme(aspect.ratio = 1) + labs(x = NULL, y = NULL) bar + coord_flip() bar + coord_polar() "],
["importing-data.html", "Chapter 3 Importing Data", " Chapter 3 Importing Data Data import chapter in r4ds http://r4ds.had.co.nz/data-import.html DataCamp Courses: https://www.datacamp.com/courses/importing-data-in-r-part-1 https://www.datacamp.com/courses/importing-data-in-r-part-2 "],
["loading-datasets.html", "3.1 Loading datasets", " 3.1 Loading datasets library(readr) look at read_ set of functions heights = read_csv(&#39;data/heights.csv&#39;) ## Parsed with column specification: ## cols( ## earn = col_double(), ## height = col_double(), ## sex = col_character(), ## ed = col_integer(), ## age = col_integer(), ## race = col_character() ## ) skip number of rows comments can be skipped col_names for no column names manually pass in column names na specifies what is “missing” in base R, read_csv, data.table::fread() string as factors! useing readr compared to base R "],
["writing-to-a-files.html", "3.2 Writing to a files", " 3.2 Writing to a files readr has a write_csv and write_tsv function Use write_rds and read_rds (similar to readRDS and saveRDS) feather can be used to share data between languages (e.g., Python) haven: SPSS, Stata, and SAS files readxl: excel files (xls, xlsx) DBI + backend (RMySQL, RSQLite, RPostgreSQL, etc) to connect to databases jsonlite xml2 rio "],
["data-transformations.html", "Chapter 4 Data Transformations", " Chapter 4 Data Transformations Data Transformation chapter in r4ds http://r4ds.had.co.nz/transform.html DataCamp Courses: https://www.datacamp.com/courses/dplyr-data-manipulation-r-tutorial https://www.datacamp.com/courses/introduction-to-the-tidyverse https://www.datacamp.com/courses/cleaning-data-in-r References: dplyr vignette: https://cran.r-project.org/web/packages/dplyr/vignettes/dplyr.html https://dplyr.tidyverse.org/ Rstudio Data Transformation Cheat Sheet Tidyverse for beginners DataCamp Cheatsheet "],
["dplyr-library.html", "4.1 dplyr library", " 4.1 dplyr library library(dplyr) ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union library(nycflights13) flights ## # A tibble: 336,776 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 1 517 515 2 830 ## 2 2013 1 1 533 529 4 850 ## 3 2013 1 1 542 540 2 923 ## 4 2013 1 1 544 545 -1 1004 ## 5 2013 1 1 554 600 -6 812 ## 6 2013 1 1 554 558 -4 740 ## 7 2013 1 1 555 600 -5 913 ## 8 2013 1 1 557 600 -3 709 ## 9 2013 1 1 557 600 -3 838 ## 10 2013 1 1 558 600 -2 753 ## # ... with 336,766 more rows, and 12 more variables: sched_arr_time &lt;int&gt;, ## # arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, ## # minute &lt;dbl&gt;, time_hour &lt;dttm&gt; The basic verbs in dplyr filter(): selects rows arrange(): reorders rows select(): selects (and re-order) columns mutate(): create new variables (columns) based on existing variables (columns) summarise(): collapses multiple values into a single value (e.g., mean, standard deviation, etc) "],
["filter.html", "4.2 Filter", " 4.2 Filter filter(flights, month == 1) ## # A tibble: 27,004 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 1 517 515 2 830 ## 2 2013 1 1 533 529 4 850 ## 3 2013 1 1 542 540 2 923 ## 4 2013 1 1 544 545 -1 1004 ## 5 2013 1 1 554 600 -6 812 ## 6 2013 1 1 554 558 -4 740 ## 7 2013 1 1 555 600 -5 913 ## 8 2013 1 1 557 600 -3 709 ## 9 2013 1 1 557 600 -3 838 ## 10 2013 1 1 558 600 -2 753 ## # ... with 26,994 more rows, and 12 more variables: sched_arr_time &lt;int&gt;, ## # arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, ## # minute &lt;dbl&gt;, time_hour &lt;dttm&gt; filter(flights, month == 1, day == 1) ## # A tibble: 842 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 1 517 515 2 830 ## 2 2013 1 1 533 529 4 850 ## 3 2013 1 1 542 540 2 923 ## 4 2013 1 1 544 545 -1 1004 ## 5 2013 1 1 554 600 -6 812 ## 6 2013 1 1 554 558 -4 740 ## 7 2013 1 1 555 600 -5 913 ## 8 2013 1 1 557 600 -3 709 ## 9 2013 1 1 557 600 -3 838 ## 10 2013 1 1 558 600 -2 753 ## # ... with 832 more rows, and 12 more variables: sched_arr_time &lt;int&gt;, ## # arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, ## # minute &lt;dbl&gt;, time_hour &lt;dttm&gt; jan1 &lt;- filter(flights, month == 1, day == 1) # jan1 = filter(flights, month == 1, day == 1) (jan1 &lt;- filter(flights, month == 1, day == 1)) ## # A tibble: 842 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 1 517 515 2 830 ## 2 2013 1 1 533 529 4 850 ## 3 2013 1 1 542 540 2 923 ## 4 2013 1 1 544 545 -1 1004 ## 5 2013 1 1 554 600 -6 812 ## 6 2013 1 1 554 558 -4 740 ## 7 2013 1 1 555 600 -5 913 ## 8 2013 1 1 557 600 -3 709 ## 9 2013 1 1 557 600 -3 838 ## 10 2013 1 1 558 600 -2 753 ## # ... with 832 more rows, and 12 more variables: sched_arr_time &lt;int&gt;, ## # arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, ## # minute &lt;dbl&gt;, time_hour &lt;dttm&gt; "],
["comparison-operators.html", "4.3 Comparison (operators)", " 4.3 Comparison (operators) Comparison operators are used to compare 2 values to one another &gt;: greater than &gt;=: greater than or equal to &lt;: less than &lt;=: less than or equal to !=: not equal ==: used to compare if two things are equal Be careful when trying to compare things that are calculations that lead to a decimal value. sqrt(2)^2 == 2 ## [1] FALSE If two things you expect to be equal are not showing up as being TRUE and the values you are comparing are decimal values, you should use the near function instead. near(sqrt(2)^2, 2) ## [1] TRUE "],
["logical-operators.html", "4.4 Logical operators", " 4.4 Logical operators Logical operators allow you to build more complex boolean conditions. |: or &amp;: and Filter the month from the flights dataset where the month is 11 (November) or 12 (December) filter(flights, month == 11 | month == 12) ## # A tibble: 55,403 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 11 1 5 2359 6 352 ## 2 2013 11 1 35 2250 105 123 ## 3 2013 11 1 455 500 -5 641 ## 4 2013 11 1 539 545 -6 856 ## 5 2013 11 1 542 545 -3 831 ## 6 2013 11 1 549 600 -11 912 ## 7 2013 11 1 550 600 -10 705 ## 8 2013 11 1 554 600 -6 659 ## 9 2013 11 1 554 600 -6 826 ## 10 2013 11 1 554 600 -6 749 ## # ... with 55,393 more rows, and 12 more variables: sched_arr_time &lt;int&gt;, ## # arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, ## # minute &lt;dbl&gt;, time_hour &lt;dttm&gt; The below code will not run like you would expect (even though this is how you would say it in your head) # filter(flights, month == 11 | 12) ## this is wrong and will not work like you expect filter(flights, month == 11 | 12) ## # A tibble: 336,776 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 1 517 515 2 830 ## 2 2013 1 1 533 529 4 850 ## 3 2013 1 1 542 540 2 923 ## 4 2013 1 1 544 545 -1 1004 ## 5 2013 1 1 554 600 -6 812 ## 6 2013 1 1 554 558 -4 740 ## 7 2013 1 1 555 600 -5 913 ## 8 2013 1 1 557 600 -3 709 ## 9 2013 1 1 557 600 -3 838 ## 10 2013 1 1 558 600 -2 753 ## # ... with 336,766 more rows, and 12 more variables: sched_arr_time &lt;int&gt;, ## # arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, ## # minute &lt;dbl&gt;, time_hour &lt;dttm&gt; Instead of writing out each boolean statment separately using |, you can use the %in% operator filter(flights, month %in% c(11, 12)) ## # A tibble: 55,403 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 11 1 5 2359 6 352 ## 2 2013 11 1 35 2250 105 123 ## 3 2013 11 1 455 500 -5 641 ## 4 2013 11 1 539 545 -6 856 ## 5 2013 11 1 542 545 -3 831 ## 6 2013 11 1 549 600 -11 912 ## 7 2013 11 1 550 600 -10 705 ## 8 2013 11 1 554 600 -6 659 ## 9 2013 11 1 554 600 -6 826 ## 10 2013 11 1 554 600 -6 749 ## # ... with 55,393 more rows, and 12 more variables: sched_arr_time &lt;int&gt;, ## # arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, ## # minute &lt;dbl&gt;, time_hour &lt;dttm&gt; WIth filter, you can also specify multiple condition (like an &amp;) filter(flights, arr_delay &lt;= 120, dep_delay &lt;= 12) ## # A tibble: 250,224 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 1 517 515 2 830 ## 2 2013 1 1 533 529 4 850 ## 3 2013 1 1 542 540 2 923 ## 4 2013 1 1 544 545 -1 1004 ## 5 2013 1 1 554 600 -6 812 ## 6 2013 1 1 554 558 -4 740 ## 7 2013 1 1 555 600 -5 913 ## 8 2013 1 1 557 600 -3 709 ## 9 2013 1 1 557 600 -3 838 ## 10 2013 1 1 558 600 -2 753 ## # ... with 250,214 more rows, and 12 more variables: sched_arr_time &lt;int&gt;, ## # arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, ## # minute &lt;dbl&gt;, time_hour &lt;dttm&gt; by default filter will also drop missing values. See the r4ds chapter for this. "],
["arrange.html", "4.5 Arrange", " 4.5 Arrange arrange(flights, year, month, day) ## # A tibble: 336,776 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 1 517 515 2 830 ## 2 2013 1 1 533 529 4 850 ## 3 2013 1 1 542 540 2 923 ## 4 2013 1 1 544 545 -1 1004 ## 5 2013 1 1 554 600 -6 812 ## 6 2013 1 1 554 558 -4 740 ## 7 2013 1 1 555 600 -5 913 ## 8 2013 1 1 557 600 -3 709 ## 9 2013 1 1 557 600 -3 838 ## 10 2013 1 1 558 600 -2 753 ## # ... with 336,766 more rows, and 12 more variables: sched_arr_time &lt;int&gt;, ## # arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, ## # minute &lt;dbl&gt;, time_hour &lt;dttm&gt; use desc to sort things in decending order arrange(flights, year, month, desc(day)) ## # A tibble: 336,776 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 31 1 2100 181 124 ## 2 2013 1 31 4 2359 5 455 ## 3 2013 1 31 7 2359 8 453 ## 4 2013 1 31 12 2250 82 132 ## 5 2013 1 31 26 2154 152 328 ## 6 2013 1 31 34 2159 155 135 ## 7 2013 1 31 37 2249 108 132 ## 8 2013 1 31 54 2250 124 152 ## 9 2013 1 31 453 500 -7 651 ## 10 2013 1 31 522 525 -3 820 ## # ... with 336,766 more rows, and 12 more variables: sched_arr_time &lt;int&gt;, ## # arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, ## # minute &lt;dbl&gt;, time_hour &lt;dttm&gt; arrange(flights, year, desc(month), day) ## # A tibble: 336,776 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 12 1 13 2359 14 446 ## 2 2013 12 1 17 2359 18 443 ## 3 2013 12 1 453 500 -7 636 ## 4 2013 12 1 520 515 5 749 ## 5 2013 12 1 536 540 -4 845 ## 6 2013 12 1 540 550 -10 1005 ## 7 2013 12 1 541 545 -4 734 ## 8 2013 12 1 546 545 1 826 ## 9 2013 12 1 549 600 -11 648 ## 10 2013 12 1 550 600 -10 825 ## # ... with 336,766 more rows, and 12 more variables: sched_arr_time &lt;int&gt;, ## # arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, ## # minute &lt;dbl&gt;, time_hour &lt;dttm&gt; "],
["select.html", "4.6 Select", " 4.6 Select select(flights, year, month, day) ## # A tibble: 336,776 x 3 ## year month day ## &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 2013 1 1 ## 2 2013 1 1 ## 3 2013 1 1 ## 4 2013 1 1 ## 5 2013 1 1 ## 6 2013 1 1 ## 7 2013 1 1 ## 8 2013 1 1 ## 9 2013 1 1 ## 10 2013 1 1 ## # ... with 336,766 more rows select(flights, year:day, arr_delay) ## # A tibble: 336,776 x 4 ## year month day arr_delay ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 2013 1 1 11 ## 2 2013 1 1 20 ## 3 2013 1 1 33 ## 4 2013 1 1 -18 ## 5 2013 1 1 -25 ## 6 2013 1 1 12 ## 7 2013 1 1 19 ## 8 2013 1 1 -14 ## 9 2013 1 1 -8 ## 10 2013 1 1 8 ## # ... with 336,766 more rows select(flights, -year) ## # A tibble: 336,776 x 18 ## month day dep_time sched_dep_time dep_delay arr_time sched_arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 1 1 517 515 2 830 819 ## 2 1 1 533 529 4 850 830 ## 3 1 1 542 540 2 923 850 ## 4 1 1 544 545 -1 1004 1022 ## 5 1 1 554 600 -6 812 837 ## 6 1 1 554 558 -4 740 728 ## 7 1 1 555 600 -5 913 854 ## 8 1 1 557 600 -3 709 723 ## 9 1 1 557 600 -3 838 846 ## 10 1 1 558 600 -2 753 745 ## # ... with 336,766 more rows, and 11 more variables: arr_delay &lt;dbl&gt;, ## # carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, ## # air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, ## # time_hour &lt;dttm&gt; select(flights, -(year:day)) ## # A tibble: 336,776 x 16 ## dep_time sched_dep_time dep_delay arr_time sched_arr_time arr_delay ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 517 515 2 830 819 11 ## 2 533 529 4 850 830 20 ## 3 542 540 2 923 850 33 ## 4 544 545 -1 1004 1022 -18 ## 5 554 600 -6 812 837 -25 ## 6 554 558 -4 740 728 12 ## 7 555 600 -5 913 854 19 ## 8 557 600 -3 709 723 -14 ## 9 557 600 -3 838 846 -8 ## 10 558 600 -2 753 745 8 ## # ... with 336,766 more rows, and 10 more variables: carrier &lt;chr&gt;, ## # flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, ## # distance &lt;dbl&gt;, hour &lt;dbl&gt;, minute &lt;dbl&gt;, time_hour &lt;dttm&gt; Other functions you can use within select: starts_with ends_with contains matches num_range # for example to create x1, x2, x3 rename(flights, &quot;tail_num&quot; = tailnum, &#39;y&#39; = year) ## # A tibble: 336,776 x 19 ## y month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 1 517 515 2 830 ## 2 2013 1 1 533 529 4 850 ## 3 2013 1 1 542 540 2 923 ## 4 2013 1 1 544 545 -1 1004 ## 5 2013 1 1 554 600 -6 812 ## 6 2013 1 1 554 558 -4 740 ## 7 2013 1 1 555 600 -5 913 ## 8 2013 1 1 557 600 -3 709 ## 9 2013 1 1 557 600 -3 838 ## 10 2013 1 1 558 600 -2 753 ## # ... with 336,766 more rows, and 12 more variables: sched_arr_time &lt;int&gt;, ## # arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tail_num &lt;chr&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, ## # minute &lt;dbl&gt;, time_hour &lt;dttm&gt; select(flights, time_hour, air_time, everything()) ## # A tibble: 336,776 x 19 ## time_hour air_time year month day dep_time sched_dep_time ## &lt;dttm&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 2013-01-01 05:00:00 227 2013 1 1 517 515 ## 2 2013-01-01 05:00:00 227 2013 1 1 533 529 ## 3 2013-01-01 05:00:00 160 2013 1 1 542 540 ## 4 2013-01-01 05:00:00 183 2013 1 1 544 545 ## 5 2013-01-01 06:00:00 116 2013 1 1 554 600 ## 6 2013-01-01 05:00:00 150 2013 1 1 554 558 ## 7 2013-01-01 06:00:00 158 2013 1 1 555 600 ## 8 2013-01-01 06:00:00 53 2013 1 1 557 600 ## 9 2013-01-01 06:00:00 140 2013 1 1 557 600 ## 10 2013-01-01 06:00:00 138 2013 1 1 558 600 ## # ... with 336,766 more rows, and 12 more variables: dep_delay &lt;dbl&gt;, ## # arr_time &lt;int&gt;, sched_arr_time &lt;int&gt;, arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, ## # flight &lt;int&gt;, tailnum &lt;chr&gt;, origin &lt;chr&gt;, dest &lt;chr&gt;, distance &lt;dbl&gt;, ## # hour &lt;dbl&gt;, minute &lt;dbl&gt; "],
["mutate.html", "4.7 Mutate", " 4.7 Mutate (flights_sml &lt;- select(flights, year:day, ends_with(&#39;delay&#39;), distance, air_time)) ## # A tibble: 336,776 x 7 ## year month day dep_delay arr_delay distance air_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2013 1 1 2 11 1400 227 ## 2 2013 1 1 4 20 1416 227 ## 3 2013 1 1 2 33 1089 160 ## 4 2013 1 1 -1 -18 1576 183 ## 5 2013 1 1 -6 -25 762 116 ## 6 2013 1 1 -4 12 719 150 ## 7 2013 1 1 -5 19 1065 158 ## 8 2013 1 1 -3 -14 229 53 ## 9 2013 1 1 -3 -8 944 140 ## 10 2013 1 1 -2 8 733 138 ## # ... with 336,766 more rows mutate(flights_sml, gain = arr_delay - dep_delay, speed = distance / air_time * 60) ## # A tibble: 336,776 x 9 ## year month day dep_delay arr_delay distance air_time gain speed ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2013 1 1 2 11 1400 227 9 370. ## 2 2013 1 1 4 20 1416 227 16 374. ## 3 2013 1 1 2 33 1089 160 31 408. ## 4 2013 1 1 -1 -18 1576 183 -17 517. ## 5 2013 1 1 -6 -25 762 116 -19 394. ## 6 2013 1 1 -4 12 719 150 16 288. ## 7 2013 1 1 -5 19 1065 158 24 404. ## 8 2013 1 1 -3 -14 229 53 -11 259. ## 9 2013 1 1 -3 -8 944 140 -5 405. ## 10 2013 1 1 -2 8 733 138 10 319. ## # ... with 336,766 more rows mutate(flights_sml, gain = arr_delay - dep_delay, speed = distance / air_time * 60, hours = air_time / 60, gain_per_hour = gain / hours ) ## # A tibble: 336,776 x 11 ## year month day dep_delay arr_delay distance air_time gain speed ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2013 1 1 2 11 1400 227 9 370. ## 2 2013 1 1 4 20 1416 227 16 374. ## 3 2013 1 1 2 33 1089 160 31 408. ## 4 2013 1 1 -1 -18 1576 183 -17 517. ## 5 2013 1 1 -6 -25 762 116 -19 394. ## 6 2013 1 1 -4 12 719 150 16 288. ## 7 2013 1 1 -5 19 1065 158 24 404. ## 8 2013 1 1 -3 -14 229 53 -11 259. ## 9 2013 1 1 -3 -8 944 140 -5 405. ## 10 2013 1 1 -2 8 733 138 10 319. ## # ... with 336,766 more rows, and 2 more variables: hours &lt;dbl&gt;, ## # gain_per_hour &lt;dbl&gt; "],
["summarize-summarise.html", "4.8 Summarize (summarise)", " 4.8 Summarize (summarise) summarize(flights, delay = mean(dep_delay, na.rm = TRUE)) ## # A tibble: 1 x 1 ## delay ## &lt;dbl&gt; ## 1 12.6 "],
["groupby.html", "4.9 Groupby", " 4.9 Groupby by_day &lt;- group_by(flights, year, month, day) summarize(by_day, delay = mean(dep_delay, na.rm = TRUE)) ## # A tibble: 365 x 4 ## # Groups: year, month [?] ## year month day delay ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 2013 1 1 11.5 ## 2 2013 1 2 13.9 ## 3 2013 1 3 11.0 ## 4 2013 1 4 8.95 ## 5 2013 1 5 5.73 ## 6 2013 1 6 7.15 ## 7 2013 1 7 5.42 ## 8 2013 1 8 2.55 ## 9 2013 1 9 2.28 ## 10 2013 1 10 2.84 ## # ... with 355 more rows Do a group by and perform multiple summarizations by_month &lt;- group_by(flights, year, month) by_month &lt;- summarize(by_month, delay = mean(dep_delay, na.rm = TRUE), delay_std = sd(dep_delay, na.rm = TRUE) ) by_month ## # A tibble: 12 x 4 ## # Groups: year [?] ## year month delay delay_std ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2013 1 10.0 36.4 ## 2 2013 2 10.8 36.3 ## 3 2013 3 13.2 40.1 ## 4 2013 4 13.9 43.0 ## 5 2013 5 13.0 39.4 ## 6 2013 6 20.8 51.5 ## 7 2013 7 21.7 51.6 ## 8 2013 8 12.6 37.7 ## 9 2013 9 6.72 35.6 ## 10 2013 10 6.24 29.7 ## 11 2013 11 5.44 27.6 ## 12 2013 12 16.6 41.9 The above code can be re-written using the pipe, %&gt;% # i&#39;m pretty sure this is easier to read and understand by_month &lt;- group_by(flights, year, month) %&gt;% summarize(delay = mean(dep_delay, na.rm = TRUE), delay_std = sd(dep_delay, na.rm = TRUE)) by_month ## # A tibble: 12 x 4 ## # Groups: year [?] ## year month delay delay_std ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2013 1 10.0 36.4 ## 2 2013 2 10.8 36.3 ## 3 2013 3 13.2 40.1 ## 4 2013 4 13.9 43.0 ## 5 2013 5 13.0 39.4 ## 6 2013 6 20.8 51.5 ## 7 2013 7 21.7 51.6 ## 8 2013 8 12.6 37.7 ## 9 2013 9 6.72 35.6 ## 10 2013 10 6.24 29.7 ## 11 2013 11 5.44 27.6 ## 12 2013 12 16.6 41.9 Otherwise you will have to create a temp variable, or write a nested expression summarize(group_by(flights, year, month), delay = mean(dep_delay, na.rm = TRUE), delay_std = sd(dep_delay, na.rm = TRUE)) ## # A tibble: 12 x 4 ## # Groups: year [?] ## year month delay delay_std ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2013 1 10.0 36.4 ## 2 2013 2 10.8 36.3 ## 3 2013 3 13.2 40.1 ## 4 2013 4 13.9 43.0 ## 5 2013 5 13.0 39.4 ## 6 2013 6 20.8 51.5 ## 7 2013 7 21.7 51.6 ## 8 2013 8 12.6 37.7 ## 9 2013 9 6.72 35.6 ## 10 2013 10 6.24 29.7 ## 11 2013 11 5.44 27.6 ## 12 2013 12 16.6 41.9 "],
["tidy-data.html", "Chapter 5 Tidy data", " Chapter 5 Tidy data Tidy data chapter is r4ds: http://r4ds.had.co.nz/tidy-data.html Hadley Wickham’s Tidy data paper http://vita.had.co.nz/papers/tidy-data.html DataCamp Courses: https://www.datacamp.com/courses/cleaning-data-in-r https://www.datacamp.com/courses/importing-cleaning-data-in-r-case-studies Resources http://tidyr.tidyverse.org/ "],
["tidyr.html", "5.1 tidyr", " 5.1 tidyr library(tidyr) table4a ## # A tibble: 3 x 3 ## country `1999` `2000` ## * &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 Afghanistan 745 2666 ## 2 Brazil 37737 80488 ## 3 China 212258 213766 "],
["gather.html", "5.2 Gather", " 5.2 Gather table4a_tidy &lt;- gather(table4a, &#39;2000&#39;, &#39;1999&#39;, key = &quot;year&quot;, value = &#39;cases&#39;) library(ggplot2) ggplot(table4a_tidy) + geom_histogram(aes(x = cases, fill = country)) ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. (table4a_tidy &lt;- table4a %&gt;% gather(&#39;2000&#39;, &#39;1999&#39;, key = &quot;year&quot;, value = &#39;cases&#39;)) ## # A tibble: 6 x 3 ## country year cases ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 Afghanistan 2000 2666 ## 2 Brazil 2000 80488 ## 3 China 2000 213766 ## 4 Afghanistan 1999 745 ## 5 Brazil 1999 37737 ## 6 China 1999 212258 library(magrittr) # this is what actuallly gives you the pipe ## ## Attaching package: &#39;magrittr&#39; ## The following object is masked from &#39;package:tidyr&#39;: ## ## extract (table4b_tidy &lt;- table4b %&gt;% gather(&#39;1999&#39;:&#39;2000&#39;, key = &#39;year&#39;, value = &#39;population&#39;)) ## # A tibble: 6 x 3 ## country year population ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 Afghanistan 1999 19987071 ## 2 Brazil 1999 172006362 ## 3 China 1999 1272915272 ## 4 Afghanistan 2000 20595360 ## 5 Brazil 2000 174504898 ## 6 China 2000 1280428583 "],
["primer-to-joins.html", "5.3 Primer to joins", " 5.3 Primer to joins library(dplyr) ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union # use double colon to specify which library you are getting a function from # base::union() table4a_tidy ## # A tibble: 6 x 3 ## country year cases ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 Afghanistan 2000 2666 ## 2 Brazil 2000 80488 ## 3 China 2000 213766 ## 4 Afghanistan 1999 745 ## 5 Brazil 1999 37737 ## 6 China 1999 212258 table4b_tidy ## # A tibble: 6 x 3 ## country year population ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; ## 1 Afghanistan 1999 19987071 ## 2 Brazil 1999 172006362 ## 3 China 1999 1272915272 ## 4 Afghanistan 2000 20595360 ## 5 Brazil 2000 174504898 ## 6 China 2000 1280428583 left_join(x = table4a_tidy, y = table4b_tidy) ## Joining, by = c(&quot;country&quot;, &quot;year&quot;) ## # A tibble: 6 x 4 ## country year cases population ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 Afghanistan 2000 2666 20595360 ## 2 Brazil 2000 80488 174504898 ## 3 China 2000 213766 1280428583 ## 4 Afghanistan 1999 745 19987071 ## 5 Brazil 1999 37737 172006362 ## 6 China 1999 212258 1272915272 "],
["spread.html", "5.4 Spread", " 5.4 Spread table2 ## # A tibble: 12 x 4 ## country year type count ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; ## 1 Afghanistan 1999 cases 745 ## 2 Afghanistan 1999 population 19987071 ## 3 Afghanistan 2000 cases 2666 ## 4 Afghanistan 2000 population 20595360 ## 5 Brazil 1999 cases 37737 ## 6 Brazil 1999 population 172006362 ## 7 Brazil 2000 cases 80488 ## 8 Brazil 2000 population 174504898 ## 9 China 1999 cases 212258 ## 10 China 1999 population 1272915272 ## 11 China 2000 cases 213766 ## 12 China 2000 population 1280428583 spread(table2, key = type, value = count) ## # A tibble: 6 x 4 ## country year cases population ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 Afghanistan 1999 745 19987071 ## 2 Afghanistan 2000 2666 20595360 ## 3 Brazil 1999 37737 172006362 ## 4 Brazil 2000 80488 174504898 ## 5 China 1999 212258 1272915272 ## 6 China 2000 213766 1280428583 "],
["separate.html", "5.5 Separate", " 5.5 Separate table3 ## # A tibble: 6 x 3 ## country year rate ## * &lt;chr&gt; &lt;int&gt; &lt;chr&gt; ## 1 Afghanistan 1999 745/19987071 ## 2 Afghanistan 2000 2666/20595360 ## 3 Brazil 1999 37737/172006362 ## 4 Brazil 2000 80488/174504898 ## 5 China 1999 212258/1272915272 ## 6 China 2000 213766/1280428583 table3 %&gt;% separate(rate, into = c(&#39;cases&#39;, &#39;population&#39;)) ## # A tibble: 6 x 4 ## country year cases population ## * &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Afghanistan 1999 745 19987071 ## 2 Afghanistan 2000 2666 20595360 ## 3 Brazil 1999 37737 172006362 ## 4 Brazil 2000 80488 174504898 ## 5 China 1999 212258 1272915272 ## 6 China 2000 213766 1280428583 table3 %&gt;% separate(rate, into = c(&#39;cases&#39;, &#39;population&#39;), sep = &#39;/&#39;) ## # A tibble: 6 x 4 ## country year cases population ## * &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Afghanistan 1999 745 19987071 ## 2 Afghanistan 2000 2666 20595360 ## 3 Brazil 1999 37737 172006362 ## 4 Brazil 2000 80488 174504898 ## 5 China 1999 212258 1272915272 ## 6 China 2000 213766 1280428583 "],
["relational-data-in-r.html", "Chapter 6 Relational Data in R", " Chapter 6 Relational Data in R Relational data chapter in r4ds http://r4ds.had.co.nz/relational-data.html DataCamp Courses: https://www.datacamp.com/courses/joining-data-in-r-with-dplyr Resources: Rstudio dplyr Cheat Sheet dplyr join reference: https://dplyr.tidyverse.org/reference/join.html "],
["create-simple-datasets.html", "6.1 Create simple datasets", " 6.1 Create simple datasets library(tibble) library(dplyr) ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union x &lt;- tribble( ~key, ~val_x, 1, &quot;x1&quot;, 2, &quot;x2&quot;, 3, &quot;x3&quot; ) x ## # A tibble: 3 x 2 ## key val_x ## &lt;dbl&gt; &lt;chr&gt; ## 1 1 x1 ## 2 2 x2 ## 3 3 x3 y &lt;- tribble( ~key, ~val_y, 1, &quot;y1&quot;, 2, &quot;y2&quot;, 4, &quot;y3&quot; ) y ## # A tibble: 3 x 2 ## key val_y ## &lt;dbl&gt; &lt;chr&gt; ## 1 1 y1 ## 2 2 y2 ## 3 4 y3 "],
["one-to-one.html", "6.2 one-to-one", " 6.2 one-to-one When you perform a join, the function and code do not change. The output of the join will be determined by whether or not you have duplicate values in your keys, and whether or not both tables you are joining have duplicate values in the keys. In a one-to-one merge, there are no duplicate keys in both tables. x %&gt;% inner_join(y, by = &#39;key&#39;) ## # A tibble: 2 x 3 ## key val_x val_y ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 x1 y1 ## 2 2 x2 y2 x %&gt;% left_join(y, by = &#39;key&#39;) ## # A tibble: 3 x 3 ## key val_x val_y ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 x1 y1 ## 2 2 x2 y2 ## 3 3 x3 &lt;NA&gt; x %&gt;% right_join(y, by = &#39;key&#39;) ## # A tibble: 3 x 3 ## key val_x val_y ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 x1 y1 ## 2 2 x2 y2 ## 3 4 &lt;NA&gt; y3 x %&gt;% full_join(y, by = &#39;key&#39;) ## # A tibble: 4 x 3 ## key val_x val_y ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 x1 y1 ## 2 2 x2 y2 ## 3 3 x3 &lt;NA&gt; ## 4 4 &lt;NA&gt; y3 "],
["many-to-one-or-one-to-many.html", "6.3 many to one OR one to many", " 6.3 many to one OR one to many In a many-to-one merge, one of the tables have duplicate keys (x &lt;- tribble( ~key, ~val_x, 1, &quot;x1&quot;, 2, &quot;x2&quot;, 3, &quot;x3&quot;, 1, &quot;x4&quot;, 1, &quot;x5&quot;, 1, &quot;x6&quot; )) ## # A tibble: 6 x 2 ## key val_x ## &lt;dbl&gt; &lt;chr&gt; ## 1 1 x1 ## 2 2 x2 ## 3 3 x3 ## 4 1 x4 ## 5 1 x5 ## 6 1 x6 (y &lt;- tribble( ~key, ~val_y, 1, &quot;y1&quot;, 2, &quot;y2&quot;, 4, &quot;y3&quot; )) ## # A tibble: 3 x 2 ## key val_y ## &lt;dbl&gt; &lt;chr&gt; ## 1 1 y1 ## 2 2 y2 ## 3 4 y3 x %&gt;% left_join(y, by = &#39;key&#39;) ## # A tibble: 6 x 3 ## key val_x val_y ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 x1 y1 ## 2 2 x2 y2 ## 3 3 x3 &lt;NA&gt; ## 4 1 x4 y1 ## 5 1 x5 y1 ## 6 1 x6 y1 "],
["many-to-many.html", "6.4 many to many", " 6.4 many to many In a many to many join, both tables will have duplicate keys in them. You end up with what’s known as a cartesian product of the keys. (x &lt;- tribble( ~key, ~val_x, 1, &quot;x1&quot;, 2, &quot;x2&quot;, 3, &quot;x3&quot;, 1, &quot;x4&quot;, 1, &quot;x5&quot;, 1, &quot;x6&quot; )) ## # A tibble: 6 x 2 ## key val_x ## &lt;dbl&gt; &lt;chr&gt; ## 1 1 x1 ## 2 2 x2 ## 3 3 x3 ## 4 1 x4 ## 5 1 x5 ## 6 1 x6 (y &lt;- tribble( ~key, ~val_y, 1, &quot;y1&quot;, 2, &quot;y2&quot;, 4, &quot;y3&quot;, 1, &quot;y4&quot;, 1, &quot;y5&quot; )) ## # A tibble: 5 x 2 ## key val_y ## &lt;dbl&gt; &lt;chr&gt; ## 1 1 y1 ## 2 2 y2 ## 3 4 y3 ## 4 1 y4 ## 5 1 y5 A many to many join creates a cartesian product x %&gt;% left_join(y, by = &#39;key&#39;) ## # A tibble: 14 x 3 ## key val_x val_y ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 1 x1 y1 ## 2 1 x1 y4 ## 3 1 x1 y5 ## 4 2 x2 y2 ## 5 3 x3 &lt;NA&gt; ## 6 1 x4 y1 ## 7 1 x4 y4 ## 8 1 x4 y5 ## 9 1 x5 y1 ## 10 1 x5 y4 ## 11 1 x5 y5 ## 12 1 x6 y1 ## 13 1 x6 y4 ## 14 1 x6 y5 "],
["multiple-keys.html", "6.5 Multiple keys", " 6.5 Multiple keys The below code won’t work, but it’s to show you that you can join by multiple keys x %&gt;% left_join(y, by = c(&#39;key&#39;, &#39;col2&#39;, &#39;col3&#39;)) "],
["different-column-names.html", "6.6 Different column names", " 6.6 Different column names You can also join tables when columns do not share the same name x %&gt;% left_join(y, by = c(&#39;key&#39; = &#39;key2&#39;, &#39;col2&#39; = &#39;other&#39;, &#39;col3&#39;)) "],
["strings.html", "Chapter 7 Strings ", " Chapter 7 Strings "],
["regular-expressions.html", "7.1 Regular Expressions", " 7.1 Regular Expressions 7.1.1 Intro Resources: More detailed phone number example: https://stackoverflow.com/questions/16699007/regular-expression-to-match-standard-10-digit-phone-number Excellent cheat sheet: https://www.rstudio.com/wp-content/uploads/2016/09/RegExCheatsheet.pdf More than you ever wanted: https://www.regular-expressions.info/tutorial.html A great package for regex in r is Hadley Wickham’s ‘stringr’ package. We’ll be using this often. library(stringr) The main idea behind regular expressions (or regex) is to find blocks of text that match a certain pattern. This pattern can be as simple as a single letter or number, or as complicated as an entire address. Some simple examples. allchars = &#39;1234567890abcdefghijklmnopqrstuvwxyz&#39; str_extract_all(allchars, &#39;1&#39;) ## [[1]] ## [1] &quot;1&quot; str_extract_all(allchars, &#39;12&#39;) ## [[1]] ## [1] &quot;12&quot; str_extract_all(allchars, &#39;13&#39;) ## [[1]] ## character(0) str_extract_all(allchars, &#39;a&#39;) ## [[1]] ## [1] &quot;a&quot; A character class is a set of characters, any one of which will match. str_extract_all(allchars, &#39;[12345]&#39;) ## [[1]] ## [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;5&quot; str_extract_all(allchars, &#39;[abcde]&#39;) ## [[1]] ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; &quot;e&quot; str_extract_all(allchars, &#39;[[:digit:]]&#39;) ## [[1]] ## [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;5&quot; &quot;6&quot; &quot;7&quot; &quot;8&quot; &quot;9&quot; &quot;0&quot; What if you wanted all numbers? There are a number of built in classes to save on typing: ‘\\d’ is all digits ‘[[:lower:]]’ is all lower case letters ‘\\s’ is all white space ‘.’ is anything at all and is known as the wildcard str_extract_all(allchars, &#39;[[:digit:]]&#39;) ## [[1]] ## [1] &quot;1&quot; &quot;2&quot; &quot;3&quot; &quot;4&quot; &quot;5&quot; &quot;6&quot; &quot;7&quot; &quot;8&quot; &quot;9&quot; &quot;0&quot; str_extract_all(allchars, &#39;[[:lower:]]&#39;) ## [[1]] ## [1] &quot;a&quot; &quot;b&quot; &quot;c&quot; &quot;d&quot; &quot;e&quot; &quot;f&quot; &quot;g&quot; &quot;h&quot; &quot;i&quot; &quot;j&quot; &quot;k&quot; &quot;l&quot; &quot;m&quot; &quot;n&quot; &quot;o&quot; &quot;p&quot; &quot;q&quot; ## [18] &quot;r&quot; &quot;s&quot; &quot;t&quot; &quot;u&quot; &quot;v&quot; &quot;w&quot; &quot;x&quot; &quot;y&quot; &quot;z&quot; str_extract_all(allchars, &#39;\\\\s&#39;) ## [[1]] ## character(0) We’ll use a motivating example to introduce some other thing you can do with regular expressions. Let’s say you wanted to extract all the phone numbers in a body of text. exampleText = &quot;Some phone numbers are 7608675309, perhaps also 403-596-4038. Some people use periods in their numbers, so 402.367.5039. We can also have things like 304 385 1029 or (760)-581-3957. How can we extract all of these?&quot; We’ll start simple and try to build expressions that are general enough to get all the numbers in the above paragraph. The first number is the easiest, how can we match on any 10 numbers? str_extract_all(exampleText, &#39;\\\\d\\\\d\\\\d\\\\d\\\\d\\\\d\\\\d\\\\d\\\\d\\\\d&#39;) ## [[1]] ## [1] &quot;7608675309&quot; More succinctly we can use a quantifier to match a given number of times: {n} will match what it preceedes it n times. str_extract_all(exampleText, &#39;\\\\d{10}&#39;) ## [[1]] ## [1] &quot;7608675309&quot; Other useful quantifiers are * to match at least 0 times, + to match at least once, and {n,m} to match between n and m times. We can use * to get the first two numbers. str_extract_all(exampleText, &#39;\\\\d{3}-*\\\\d{3}-*\\\\d{4}&#39;) ## [[1]] ## [1] &quot;7608675309&quot; &quot;403-596-4038&quot; Sometimes the number groups are separated by -, sometimes by ‘.’. What happens if we try to get the number separated by periods? str_extract_all(exampleText, &#39;\\\\d{3}.*\\\\d{3}.*\\\\d{4}&#39;) ## [[1]] ## [1] &quot;7608675309, perhaps also 403-596-4038. Some people use periods in their numbers, so 402.367.5039. We can also have things like 304 385 1029 or (760)-581-3957&quot; What happened? Since the period is the wildcard it matched all kinds of things. If we want to treat the period literally, instead of as a special character, we need to escape it with double backslashes: str_extract_all(exampleText, &#39;\\\\d{3}\\\\.*\\\\d{3}\\\\.*\\\\d{4}&#39;) ## [[1]] ## [1] &quot;7608675309&quot; &quot;402.367.5039&quot; Now it’s treating period as a literal character. We can combine the expression matching period to the one matching - using character classes: str_extract_all(exampleText, &#39;\\\\d{3}[-\\\\.]*\\\\d{3}[-\\\\.]*\\\\d{4}&#39;) ## [[1]] ## [1] &quot;7608675309&quot; &quot;403-596-4038&quot; &quot;402.367.5039&quot; The pattern ’[-\\.]*’ will match either - or period at least 0 times. If you epect phone numbers with some other delimiter, you can toss it in that character class just the same. We can use the same idea to capture the space separated one. str_extract_all(exampleText, &#39;\\\\d{3}[-\\\\.\\\\s]*\\\\d{3}[-\\\\.\\\\s]*\\\\d{4}&#39;) ## [[1]] ## [1] &quot;7608675309&quot; &quot;403-596-4038&quot; &quot;402.367.5039&quot; &quot;304 385 1029&quot; The last challenge is getting the number with the parentheses. We can use the same idea. Note that since parenthese are a special character we need to escape them. str_extract_all(exampleText, &#39;\\\\(*\\\\d{3}\\\\)*[-\\\\.\\\\s]*\\\\d{3}[-\\\\.\\\\s]*\\\\d{4}&#39;) ## [[1]] ## [1] &quot;7608675309&quot; &quot;403-596-4038&quot; &quot;402.367.5039&quot; &quot;304 385 1029&quot; ## [5] &quot;(760)-581-3957&quot; 7.1.2 Basic Web Scraping Example Regular expressions are very useful in the context of web scraping. This example is from a small scraping job we did on the Pulaski Board of Supervisors website to extract their meeting minutes. First, we should have a look at their website to get a lay of the land. It’s at: http://www.pulaskicounty.org/Board-of-Supervisors.html library(XML) rooturl = &quot;http://www.pulaskicounty.org/Board-of-Supervisors.html&quot; bosMainPage = htmlParse(rooturl) bosMainPage ## &lt;!DOCTYPE html&gt; ## &lt;html lang=&quot;en&quot;&gt; ## &lt;head&gt; ## &lt;title&gt;Pulaski County&lt;/title&gt; ## &lt;link rel=&quot;shortcut icon&quot; type=&quot;image/png&quot; href=&quot;images/favicon.png&quot;&gt; ## &lt;meta charset=&quot;utf-8&quot;&gt; ## &lt;link href=&quot;css/reset.css&quot; rel=&quot;stylesheet&quot;&gt; ## &lt;link href=&quot;css/layout.css&quot; rel=&quot;stylesheet&quot;&gt; ## &lt;link href=&quot;css/style.css&quot; rel=&quot;stylesheet&quot;&gt; ## &lt;!--[if lt IE 7]&gt; ## &lt;script src=&quot;http://info.template-help.com/files/ie6_warning/ie6_script_other.js&quot;&gt;&lt;/script&gt; ## &lt;![endif]--&gt;&lt;!--[if IE]&gt; ## &lt;script src=&quot;js/html5.js&quot;&gt;&lt;/script&gt; ## &lt;![endif]--&gt; ## &lt;/head&gt; ## &lt;body id=&quot;page2&quot;&gt; ## &lt;div id=&quot;main&quot;&gt; ## &lt;!-- header --&gt; ## &lt;header&gt;&lt;h1&gt;&lt;a href=&quot;index.html&quot;&gt;&lt;span&gt;County government&lt;/span&gt;&lt;/a&gt;&lt;/h1&gt; ## &lt;h2&gt;Orchestrated By Nature™&lt;/h2&gt; ## &lt;img class=&quot;Nature&quot; src=&quot;images/PulaskiNature.png&quot;&gt;&lt;form id=&quot;search_form&quot;&gt; ## &lt;input type=&quot;text&quot; value=&quot;Searching ...&quot; onblur=&quot;if(this.value==&#39;&#39;) this.value=&#39;Searching ...&#39;&quot; onfocus=&quot;if(this.value ==&#39;Searching ...&#39; ) this.value=&#39;&#39;&quot;&gt;&lt;input type=&quot;image&quot; src=&quot;images/search_button.jpg&quot; alt=&quot;Start searching&quot;&gt; ## &lt;/form&gt; ## ## &lt;/header&gt;&lt;!-- nav --&gt;&lt;nav&gt;&lt;ul&gt; ## &lt;li class=&quot;first&quot;&gt;&lt;a href=&quot;index.html&quot;&gt;&lt;span&gt;Home&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; ## &lt;li class=&quot;active&quot;&gt;&lt;a href=&quot;Departments.html&quot;&gt;&lt;span&gt;Departments&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; ## ## &lt;li&gt;&lt;a href=&quot;Things-to-Do.html&quot;&gt;&lt;span&gt;Attractions&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; ## &lt;li&gt;&lt;a href=&quot;Employees-Employment.html&quot;&gt;&lt;span&gt;Employees/Employment&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; ## &lt;li&gt;&lt;a href=&quot;Companies.html&quot;&gt;&lt;span&gt;Economic Development&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; ## &lt;li class=&quot;last&quot;&gt;&lt;a href=&quot;Documents-Forms.html&quot;&gt;&lt;span&gt;Documents/Forms&lt;/span&gt;&lt;/a&gt;&lt;/li&gt; ## &lt;/ul&gt;&lt;/nav&gt;&lt;!-- content --&gt;&lt;section id=&quot;content&quot;&gt;&lt;div id=&quot;indent&quot;&gt; ## &lt;div class=&quot;wrapper&quot;&gt; ## &lt;article class=&quot;col-1&quot;&gt;&lt;div class=&quot;wrapper&quot;&gt; ## &lt;div class=&quot;block-1&quot;&gt; ## &lt;div class=&quot;box&quot;&gt; ## &lt;div class=&quot;inner&quot;&gt; ## &lt;h3&gt;Categories:&lt;/h3&gt; ## &lt;ul class=&quot;list2&quot;&gt; ## &lt;li class=&quot;light&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://www.boarddocs.com/va/copva/Board.nsf&quot;&gt;BoardDocs&lt;/a&gt;&lt;/li&gt; ## &lt;li&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.pulaskichamber.info/&quot;&gt;Chamber of Commerce&lt;/a&gt;&lt;/li&gt; ## &lt;li class=&quot;light&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;files/Churches.pdf&quot;&gt;Churches&lt;/a&gt;&lt;/li&gt; ## &lt;li&gt;&lt;a href=&quot;telephone-numbers.htm&quot;&gt;Contact Directory&lt;/a&gt;&lt;/li&gt; ## &lt;li class=&quot;light&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;mailto:info@pulaskicounty.org&quot;&gt;Contact Us&lt;/a&gt;&lt;/li&gt; ## &lt;li&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://www.facebook.com/PulaskiVirginia&quot;&gt;County Blog&lt;/a&gt;&lt;/li&gt; ## &lt;li class=&quot;light&quot;&gt;&lt;a href=&quot;Employment-Opportunities.html&quot;&gt;Employment Opportunities&lt;/a&gt;&lt;/li&gt; ## &lt;li&gt;&lt;a target=&quot;_blank&quot; href=&quot;GIS.html&quot;&gt;GIS&lt;/a&gt;&lt;/li&gt; ## &lt;li class=&quot;light&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.pclibs.org/&quot;&gt;Library&lt;/a&gt;&lt;/li&gt; ## &lt;li&gt;&lt;a href=&quot;Links.html&quot;&gt;Links&lt;/a&gt;&lt;/li&gt; ## &lt;li class=&quot;light&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.pcva.us/&quot;&gt;Schools&lt;/a&gt;&lt;/li&gt; ## &lt;li&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.dublintown.org/&quot;&gt;Town of Dublin&lt;/a&gt;&lt;/li&gt; ## &lt;li class=&quot;light&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.pulaskitown.org/&quot;&gt;Town of Pulaski&lt;/a&gt;&lt;/li&gt; ## &lt;li&gt;&lt;a href=&quot;Website-Links-Statement.html&quot;&gt;Web Site Links Statement&lt;/a&gt;&lt;/li&gt; ## &lt;/ul&gt; ## &lt;/div&gt; ## &lt;/div&gt; ## &lt;/div&gt; ## &lt;div class=&quot;block-2&quot;&gt; ## &lt;h3&gt;Pulaski County Board of Supervisors&lt;/h3&gt; ## Andy McCready, Chairman &lt;br&gt; ## Massie District &lt;br&gt; ## Administration Office: 540-980 -7705&lt;br&gt; ## Business: 540-980-8700&lt;br&gt; ## e-mail: &lt;a href=&quot;mailto:amc@pulaskicounty.org&quot;&gt; amc@pulaskicounty.org&lt;/a&gt;&lt;br&gt;&lt;br&gt; ## ## Charles R. Bopp, Vice-Chairman&lt;br&gt; ## Robinson District&lt;br&gt; ## Home: 540-980-2757 &lt;br&gt; ## e-mail: &lt;a href=&quot;mailto:cbopp@pulaskicounty.org&quot;&gt;cbopp@pulaskicounty.org&lt;/a&gt;&lt;br&gt;&lt;br&gt; ## ## Joseph Guthrie&lt;br&gt; ## Cloyd District&lt;br&gt; ## Home: 540-674-2423&lt;br&gt; ## e-mail: &lt;a href=&quot;mailto:jwguthrie@pulaskicounty.org&quot;&gt;jwguthrie@pulaskicounty.org&lt;/a&gt;&lt;br&gt;&lt;br&gt; ## ## Ranny E. O’Dell &lt;br&gt; ## Ingles District &lt;br&gt; ## Business: 540-980-3407&lt;br&gt; ## e-mail: &lt;a href=&quot;mailto:odellroho289@aol.com&quot;&gt; odellroho289@aol.com&lt;/a&gt;&lt;br&gt;&lt;br&gt; ## ## Dean K. Pratt &lt;br&gt; ## Draper District&lt;br&gt; ## Home: 540-980-7150&lt;br&gt; ## e-mail: &lt;a href=&quot;mailto:dpratt@pulaskicounty.org&quot;&gt; dpratt@pulaskicounty.org&lt;/a&gt;&lt;br&gt;&lt;br&gt; ## ## Timothy Kirtner&lt;br&gt; ## County Attorney&lt;br&gt; ## c/o Gilmer Sadler Law Offices&lt;br&gt; ## P. O. Box 878&lt;br&gt; ## Pulaski, VA 24301&lt;br&gt; ## Work: 540-980-1360&lt;br&gt; ## e-mail: &lt;a href=&quot;mailto:tkirtner@gsish.com&quot;&gt;tkirtner@gsish.com&lt;/a&gt; ## &lt;br&gt;&lt;p style=&quot;border-bottom:1px solid rgba(100, 100, 100, 0.05);&quot;&gt;&lt;/p&gt; ## &lt;h3&gt;Procedures, Vision, and Goals Statement&lt;/h3&gt; ## &lt;a target=&quot;_blank&quot; href=&quot;bos/Board%20of%20Supervisors%20Procedures.pdf&quot;&gt;Board of Supervisiors Procedures regarding citizens comments&lt;/a&gt; ## &lt;a target=&quot;_blank&quot; href=&quot;bos/2004-2007%20Board%20Goals.htm&quot;&gt;County Vision and Goals Statement&lt;/a&gt; ## &lt;br&gt;&lt;p style=&quot;border-bottom:1px solid rgba(100, 100, 100, 0.05);&quot;&gt;&lt;/p&gt; ## &lt;h3&gt;Citizen Comments&lt;/h3&gt; ## &lt;a href=&quot;files/Citizen%20Comments%20-%20Highway%20Matters.pdf&quot;&gt;Highway Matters&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p style=&quot;border-bottom:1px solid rgba(100, 100, 100, 0.05);&quot;&gt;&lt;/p&gt; ## ## &lt;h3&gt;Noise Ordinance&lt;/h3&gt; ## &lt;a href=&quot;files/Noise%20Ordinance%20Final.pdf&quot;&gt;Noise Ordinance&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;br&gt;&lt;p style=&quot;border-bottom:1px solid rgba(100, 100, 100, 0.05);&quot;&gt;&lt;/p&gt; ## ## &lt;h3&gt;2016-2017 Budget&lt;/h3&gt; ## &lt;a href=&quot;Budget/FY%202016%202017/Budget%20Advertisement.pdf&quot;&gt;Budget Advertisement&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;a href=&quot;Budget/FY%202016%202017/Revenue%20Chart.pdf&quot;&gt;Revenue Chart ## &lt;br&gt;&lt;/a&gt; ## &lt;a href=&quot;Budget/FY%202016%202017/Revenue%20History%20Chart.pdf&quot;&gt;Revenue History Chart ## &lt;/a&gt;&lt;br&gt;&lt;a href=&quot;Budget/FY%202016%202017/Revenue%20Chart.pdf&quot;&gt;Revenue Chart ## &lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;a href=&quot;Budget/FY%202016%202017/Expenditure%20Chart.pdf&quot;&gt;Expenditure Chart ## &lt;/a&gt;&lt;br&gt;&lt;a href=&quot;Budget/FY%202016%202017/Expenditure%20Summary.pdf&quot;&gt;Expenditure Summary&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;Budget/FY%202016%202017/Expenditure%20History%20Chart.pdf&quot;&gt;Expenditure History Chart ## &lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;a href=&quot;Budget/FY%202016%202017/BOS%202016-17%20CIP%20BY%20PRIORITY%20RANK.pdf&quot;&gt;Capital Improvement Plans for the Board of Supervisors &lt;/a&gt;&lt;br&gt;&lt;a href=&quot;Budget/FY%202016%202017/PSA%202016-17%20CIP%20BY%20PRIORITY%20RANK.pdf&quot;&gt;Capital Improvement Plans for the Public Service Authority&lt;/a&gt; ## &lt;br&gt;&lt;p style=&quot;border-bottom:1px solid rgba(100, 100, 100, 0.05);&quot;&gt;&lt;/p&gt; ## ## &lt;h3&gt;2015-2016 Budget&lt;/h3&gt; ## &lt;a href=&quot;Budget/FY%202015%202016/Budget%20Advertisement.pdf&quot;&gt;Budget Advertisement&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;Budget/FY%202015%202016/Revenue%20Projections.pdf&quot;&gt;Revenue Projections ## &lt;br&gt;&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;Budget/FY%202015%202016/Revenue%20History%20Chart.pdf&quot;&gt;Revenue History Chart ## &lt;/a&gt;&lt;br&gt;&lt;a href=&quot;Budget/FY%202015%202016/Projected%20Revenues.pdf&quot;&gt;Projected Revenues ## &lt;/a&gt;&lt;br&gt;&lt;a href=&quot;Budget/FY%202015%202016/Expenditure%20Summary.pdf&quot;&gt;Expenditure Summary&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;a href=&quot;Budget/FY%202015%202016/Expenditure%20History%20Chart.pdf&quot;&gt;Expenditure History Chart ## &lt;/a&gt;&lt;br&gt;&lt;a href=&quot;Budget/FY%202015%202016/Proposed%20Expenditures.pdf&quot;&gt;Projected Expenditures ## &lt;/a&gt; ## &lt;br&gt;&lt;p style=&quot;border-bottom:1px solid rgba(100, 100, 100, 0.05);&quot;&gt;&lt;/p&gt; ## &lt;h3&gt;Regional Tax Rate Comparisons&lt;/h3&gt; ## &lt;a href=&quot;Budget/FY%202015%202016/Comparison%20of%20Real%20Estate%20Rates.pdf&quot;&gt;Comparison of Real Estate Rates ## &lt;/a&gt;&lt;br&gt;&lt;a href=&quot;Budget/FY%202015%202016/Personal%20Property%20Tax%20Rate%20Comparison.pdf&quot;&gt;Personal Property Taxes ## &lt;br&gt;&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;p style=&quot;border-bottom:1px solid rgba(100, 100, 100, 0.05);&quot;&gt;&lt;/p&gt; ## &lt;h3&gt;Pulaski County Audits&lt;/h3&gt; ## &lt;a target=&quot;_blank&quot; href=&quot;Audits.html&quot;&gt;County Audit Reports&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;p style=&quot;border-bottom:1px solid rgba(100, 100, 100, 0.05);&quot;&gt;&lt;/p&gt; ## &lt;h3&gt;Pulaski County Goals&lt;/h3&gt; ## &lt;a target=&quot;_blank&quot; href=&quot;files/Goals-Project.pdf&quot;&gt;Goals and Projects&lt;/a&gt;&lt;br&gt;&lt;br&gt;&lt;p style=&quot;border-bottom:1px solid rgba(100, 100, 100, 0.05);&quot;&gt;&lt;/p&gt; ## &lt;h3&gt;Roads&lt;/h3&gt; ## &lt;a target=&quot;_blank&quot; href=&quot;bos/2008%20Six-Year%20Plan,%20and%20Waiting%20lists.pdf&quot;&gt;Six Year Road Improvement Plan&lt;/a&gt;&lt;br&gt;&lt;a target=&quot;_blank&quot; href=&quot;bos/2008%20Six-Year%20Waiting%20lists.pdf&quot;&gt;Six Year Road Improvement Waiting List&lt;/a&gt;&lt;br&gt;&lt;a target=&quot;_blank&quot; href=&quot;files/Road%20Names.pdf&quot;&gt;County Road Names&lt;/a&gt; ## &lt;div class=&quot;image_list extra&quot;&gt; ## &lt;div class=&quot;clear&quot;&gt;&lt;/div&gt; ## &lt;/div&gt; ## &lt;div class=&quot;clear&quot;&gt;&lt;/div&gt; ## &lt;/div&gt; ## &lt;div class=&quot;clear&quot;&gt;&lt;/div&gt; ## &lt;/div&gt; ## &lt;/article&gt;&lt;article class=&quot;col-2&quot;&gt;&lt;div class=&quot;box indent&quot;&gt; ## &lt;div class=&quot;inner&quot;&gt; ## &lt;h3&gt;Departments&lt;/h3&gt; ## &lt;ul class=&quot;list2&quot;&gt; ## &lt;li class=&quot;light&quot;&gt;&lt;a target=&quot;_blank&quot; href=&quot;files/Animal%20Control.pdf&quot;&gt;Animal Control&lt;/a&gt;&lt;/li&gt; ## &lt;li&gt;&lt;a href=&quot;Board-of-Supervisors.html&quot;&gt;Board of Supervisors&lt;/a&gt;&lt;/li&gt; ## &lt;li class=&quot;light&quot;&gt;&lt;a href=&quot;Building-Department.html&quot;&gt;Building Department&lt;/a&gt;&lt;/li&gt; ## &lt;li&gt;&lt;a href=&quot;Commissioner-of-the-Revenue.html&quot;&gt;Commissioner of the Revenue&lt;/a&gt;&lt;/li&gt; ## &lt;li class=&quot;light&quot;&gt;&lt;a href=&quot;Courts.html&quot;&gt;Courts&lt;/a&gt;&lt;/li&gt; ## &lt;li&gt;&lt;a href=&quot;Emergency-Management.html&quot;&gt;Emergency Management&lt;/a&gt;&lt;/li&gt; ## &lt;li class=&quot;light&quot;&gt;&lt;a href=&quot;Planning-Zoning.html&quot;&gt;Planning and Zoning Office&lt;/a&gt;&lt;/li&gt; ## &lt;li&gt;&lt;a href=&quot;Recreation.html&quot;&gt;Recreation&lt;/a&gt;&lt;/li&gt; ## &lt;li class=&quot;light&quot;&gt;&lt;a href=&quot;Registrar.html&quot;&gt;Registrar&lt;/a&gt;&lt;/li&gt; ## &lt;li&gt;&lt;a href=&quot;Treasurer&#39;s-Office.html&quot;&gt;Treasurer&#39;s Office&lt;/a&gt;&lt;/li&gt; ## &lt;li class=&quot;light&quot;&gt;&lt;a href=&quot;Utilities-PSA.html&quot;&gt;Utilities - PSA&lt;/a&gt;&lt;/li&gt; ## ## &lt;/ul&gt; ## &lt;/div&gt; ## &lt;/div&gt; ## &lt;div class=&quot;inner&quot;&gt; ## &lt;p&gt;The Pulaski County Board of Supervisors meet regularly on the fourth Monday of each month beginning at 7:00 pm in the Board Room of the County Administration Building located at 143 Third Street, N.W. in the town of Pulaski.&lt;/p&gt; ## &lt;p&gt;Board Minutes are not posted until officially approved by the Board of Supervisors. This Approval is normally completed at the next meeting of the board. &lt;/p&gt; ## &lt;h3 class=&quot;extra red&quot;&gt;Minutes and Agendas&lt;/h3&gt; ## &lt;p class=&quot;aligncenter2&quot;&gt; ## &lt;a href=&quot;Board-of-Supervisors-Minutes-2017.html&quot;&gt;2017&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;Board-of-Supervisors-Minutes-2016.html&quot;&gt;2016&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;Board-of-Supervisors-Minutes-2015.html&quot;&gt;2015&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;Board-of-Supervisors-Minutes-2014.html&quot;&gt;2014&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;Board-of-Supervisors-Minutes-2013.html&quot;&gt;2013&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;Board-of-Supervisors-Minutes-2012.html&quot;&gt;2012&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;Board-of-Supervisors-Minutes-2011.html&quot;&gt;2011&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;Board-of-Supervisors-Minutes-2010.html&quot;&gt;2010&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;Board-of-Supervisors-Minutes-2009.html&quot;&gt;2009&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;Board-of-Supervisors-Minutes-2008.html&quot;&gt;2008&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;Board-of-Supervisors-Minutes-2007.html&quot;&gt;2007&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;Board-of-Supervisors-Minutes-2006.html&quot;&gt;2006&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;Board-of-Supervisors-Minutes-2005.html&quot;&gt;2005&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;Board-of-Supervisors-Minutes-2004.html&quot;&gt;2004&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;Board-of-Supervisors-Minutes-2003.html&quot;&gt;2003&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;Board-of-Supervisors-Minutes-2002.html&quot;&gt;2002&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;Board-of-Supervisors-Minutes-2000.html&quot;&gt;2000&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;Board-of-Supervisors-Minutes-2001.html&quot;&gt;2001&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;Board-of-Supervisors-Minutes-1999.html&quot;&gt;1999&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;Board-of-Supervisors-Minutes-1998.html&quot;&gt;1998&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;Board-of-Supervisors-Minutes-1997.html&quot;&gt;1997&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;Board-of-Supervisors-Minutes-1996.html&quot;&gt;1996&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;Board-of-Supervisors-Minutes-1995.html&quot;&gt;1995&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;Board-of-Supervisors-Minutes-1994.html&quot;&gt;1994&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;Board-of-Supervisors-Minutes-1993.html&quot;&gt;1993&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;Board-of-Supervisors-Minutes-1992.html&quot;&gt;1992&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;Board-of-Supervisors-Minutes-1991.html&quot;&gt;1991&lt;/a&gt;&lt;br&gt;&lt;/p&gt; ## &lt;img class=&quot;sidebarlogo&quot; src=&quot;images/logored.png&quot; alt=&quot;county seal&quot; width=&quot;150&quot; height=&quot;145&quot;&gt;&lt;p class=&quot;homeimg&quot;&gt;County of Pulaski, VA&lt;br&gt; ## 143 3rd ST NW, Suite 1&lt;br&gt; ## Pulaski VA 24301&lt;br&gt; ## 540-980-7705&lt;br&gt;&lt;/p&gt; ## &lt;/div&gt; ## &lt;/article&gt; ## &lt;/div&gt; ## &lt;/div&gt; ## &lt;/section&gt;&lt;!-- footer --&gt;&lt;footer&gt;&lt;div class=&quot;inner&quot;&gt; ## &lt;div class=&quot;wrapper&quot;&gt; ## &lt;div class=&quot;col-1&quot;&gt; ## &lt;p class=&quot;copy&quot;&gt;&lt;strong&gt;Pulaski County&lt;/strong&gt;  © 2014&lt;br&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://www.facebook.com/PulaskiVirginia/timeline?ref=page_internal&quot;&gt; ## &lt;img src=&quot;images/facebooksmall.png&quot;&gt;&lt;/a&gt;&lt;/p&gt; ## &lt;div&gt; ## &lt;/div&gt; ## &lt;/div&gt; ## &lt;div class=&quot;col-2&quot;&gt; ## &lt;ul class=&quot;footer_list&quot;&gt; ## &lt;li&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://www.boarddocs.com/va/copva/Board.nsf&quot;&gt;BoardDocs&lt;/a&gt;&lt;/li&gt; ## &lt;li&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.pulaskichamber.info/&quot;&gt;Chamber of Commerce&lt;/a&gt;&lt;/li&gt; ## &lt;li&gt;&lt;a target=&quot;_blank&quot; href=&quot;files/Churches.pdf&quot;&gt;Churches&lt;/a&gt;&lt;/li&gt; ## &lt;li&gt;&lt;a href=&quot;telephone-numbers.htm&quot;&gt;Contact Directory&lt;/a&gt;&lt;/li&gt; ## &lt;/ul&gt; ## &lt;/div&gt; ## &lt;div class=&quot;col-3&quot;&gt; ## &lt;ul class=&quot;footer_list&quot;&gt; ## &lt;li&gt;&lt;a target=&quot;_blank&quot; href=&quot;mailto:info@pulaskicounty.org&quot;&gt;Contact Us&lt;/a&gt;&lt;/li&gt; ## &lt;li&gt;&lt;a target=&quot;_blank&quot; href=&quot;https://www.facebook.com/PulaskiVirginia&quot;&gt;County Blog&lt;/a&gt;&lt;/li&gt; ## &lt;li&gt;&lt;a target=&quot;_blank&quot; href=&quot;GIS.html&quot;&gt;GIS&lt;/a&gt;&lt;/li&gt; ## &lt;li&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.pclibs.org/&quot;&gt;Library&lt;/a&gt;&lt;/li&gt; ## &lt;/ul&gt; ## &lt;/div&gt; ## &lt;div class=&quot;col-4&quot;&gt; ## &lt;ul class=&quot;footer_list&quot;&gt; ## &lt;li&gt;&lt;a href=&quot;links.html&quot;&gt;Links&lt;/a&gt;&lt;/li&gt; ## &lt;li&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.pcva.us/&quot;&gt;Schools&lt;/a&gt;&lt;/li&gt; ## &lt;li&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.dublintown.org/&quot;&gt;Town of Dublin&lt;/a&gt;&lt;/li&gt; ## &lt;li&gt;&lt;a target=&quot;_blank&quot; href=&quot;http://www.pulaskitown.org/&quot;&gt;Town of Pulaski&lt;/a&gt;&lt;/li&gt; ## &lt;/ul&gt; ## &lt;/div&gt; ## &lt;/div&gt; ## &lt;/div&gt; ## &lt;/footer&gt; ## &lt;/div&gt; ## ## ## &lt;/body&gt; ## &lt;/html&gt; ## links = xpathSApply(bosMainPage, &quot;//a/@href&quot;) links ## href ## &quot;index.html&quot; ## href ## &quot;index.html&quot; ## href ## &quot;Departments.html&quot; ## href ## &quot;Things-to-Do.html&quot; ## href ## &quot;Employees-Employment.html&quot; ## href ## &quot;Companies.html&quot; ## href ## &quot;Documents-Forms.html&quot; ## href ## &quot;https://www.boarddocs.com/va/copva/Board.nsf&quot; ## href ## &quot;http://www.pulaskichamber.info/&quot; ## href ## &quot;files/Churches.pdf&quot; ## href ## &quot;telephone-numbers.htm&quot; ## href ## &quot;mailto:info@pulaskicounty.org&quot; ## href ## &quot;https://www.facebook.com/PulaskiVirginia&quot; ## href ## &quot;Employment-Opportunities.html&quot; ## href ## &quot;GIS.html&quot; ## href ## &quot;http://www.pclibs.org/&quot; ## href ## &quot;Links.html&quot; ## href ## &quot;http://www.pcva.us/&quot; ## href ## &quot;http://www.dublintown.org/&quot; ## href ## &quot;http://www.pulaskitown.org/&quot; ## href ## &quot;Website-Links-Statement.html&quot; ## href ## &quot;mailto:amc@pulaskicounty.org&quot; ## href ## &quot;mailto:cbopp@pulaskicounty.org&quot; ## href ## &quot;mailto:jwguthrie@pulaskicounty.org&quot; ## href ## &quot;mailto:odellroho289@aol.com&quot; ## href ## &quot;mailto:dpratt@pulaskicounty.org&quot; ## href ## &quot;mailto:tkirtner@gsish.com&quot; ## href ## &quot;bos/Board of Supervisors Procedures.pdf&quot; ## href ## &quot;bos/2004-2007 Board Goals.htm&quot; ## href ## &quot;files/Citizen Comments - Highway Matters.pdf&quot; ## href ## &quot;files/Noise Ordinance Final.pdf&quot; ## href ## &quot;Budget/FY 2016 2017/Budget Advertisement.pdf&quot; ## href ## &quot;Budget/FY 2016 2017/Revenue Chart.pdf&quot; ## href ## &quot;Budget/FY 2016 2017/Revenue History Chart.pdf&quot; ## href ## &quot;Budget/FY 2016 2017/Revenue Chart.pdf&quot; ## href ## &quot;Budget/FY 2016 2017/Expenditure Chart.pdf&quot; ## href ## &quot;Budget/FY 2016 2017/Expenditure Summary.pdf&quot; ## href ## &quot;Budget/FY 2016 2017/Expenditure History Chart.pdf&quot; ## href ## &quot;Budget/FY 2016 2017/BOS 2016-17 CIP BY PRIORITY RANK.pdf&quot; ## href ## &quot;Budget/FY 2016 2017/PSA 2016-17 CIP BY PRIORITY RANK.pdf&quot; ## href ## &quot;Budget/FY 2015 2016/Budget Advertisement.pdf&quot; ## href ## &quot;Budget/FY 2015 2016/Revenue Projections.pdf&quot; ## href ## &quot;Budget/FY 2015 2016/Revenue History Chart.pdf&quot; ## href ## &quot;Budget/FY 2015 2016/Projected Revenues.pdf&quot; ## href ## &quot;Budget/FY 2015 2016/Expenditure Summary.pdf&quot; ## href ## &quot;Budget/FY 2015 2016/Expenditure History Chart.pdf&quot; ## href ## &quot;Budget/FY 2015 2016/Proposed Expenditures.pdf&quot; ## href ## &quot;Budget/FY 2015 2016/Comparison of Real Estate Rates.pdf&quot; ## href ## &quot;Budget/FY 2015 2016/Personal Property Tax Rate Comparison.pdf&quot; ## href ## &quot;Audits.html&quot; ## href ## &quot;files/Goals-Project.pdf&quot; ## href ## &quot;bos/2008 Six-Year Plan, and Waiting lists.pdf&quot; ## href ## &quot;bos/2008 Six-Year Waiting lists.pdf&quot; ## href ## &quot;files/Road Names.pdf&quot; ## href ## &quot;files/Animal Control.pdf&quot; ## href ## &quot;Board-of-Supervisors.html&quot; ## href ## &quot;Building-Department.html&quot; ## href ## &quot;Commissioner-of-the-Revenue.html&quot; ## href ## &quot;Courts.html&quot; ## href ## &quot;Emergency-Management.html&quot; ## href ## &quot;Planning-Zoning.html&quot; ## href ## &quot;Recreation.html&quot; ## href ## &quot;Registrar.html&quot; ## href ## &quot;Treasurer&#39;s-Office.html&quot; ## href ## &quot;Utilities-PSA.html&quot; ## href ## &quot;Board-of-Supervisors-Minutes-2017.html&quot; ## href ## &quot;Board-of-Supervisors-Minutes-2016.html&quot; ## href ## &quot;Board-of-Supervisors-Minutes-2015.html&quot; ## href ## &quot;Board-of-Supervisors-Minutes-2014.html&quot; ## href ## &quot;Board-of-Supervisors-Minutes-2013.html&quot; ## href ## &quot;Board-of-Supervisors-Minutes-2012.html&quot; ## href ## &quot;Board-of-Supervisors-Minutes-2011.html&quot; ## href ## &quot;Board-of-Supervisors-Minutes-2010.html&quot; ## href ## &quot;Board-of-Supervisors-Minutes-2009.html&quot; ## href ## &quot;Board-of-Supervisors-Minutes-2008.html&quot; ## href ## &quot;Board-of-Supervisors-Minutes-2007.html&quot; ## href ## &quot;Board-of-Supervisors-Minutes-2006.html&quot; ## href ## &quot;Board-of-Supervisors-Minutes-2005.html&quot; ## href ## &quot;Board-of-Supervisors-Minutes-2004.html&quot; ## href ## &quot;Board-of-Supervisors-Minutes-2003.html&quot; ## href ## &quot;Board-of-Supervisors-Minutes-2002.html&quot; ## href ## &quot;Board-of-Supervisors-Minutes-2000.html&quot; ## href ## &quot;Board-of-Supervisors-Minutes-2001.html&quot; ## href ## &quot;Board-of-Supervisors-Minutes-1999.html&quot; ## href ## &quot;Board-of-Supervisors-Minutes-1998.html&quot; ## href ## &quot;Board-of-Supervisors-Minutes-1997.html&quot; ## href ## &quot;Board-of-Supervisors-Minutes-1996.html&quot; ## href ## &quot;Board-of-Supervisors-Minutes-1995.html&quot; ## href ## &quot;Board-of-Supervisors-Minutes-1994.html&quot; ## href ## &quot;Board-of-Supervisors-Minutes-1993.html&quot; ## href ## &quot;Board-of-Supervisors-Minutes-1992.html&quot; ## href ## &quot;Board-of-Supervisors-Minutes-1991.html&quot; ## href ## &quot;https://www.facebook.com/PulaskiVirginia/timeline?ref=page_internal&quot; ## href ## &quot;https://www.boarddocs.com/va/copva/Board.nsf&quot; ## href ## &quot;http://www.pulaskichamber.info/&quot; ## href ## &quot;files/Churches.pdf&quot; ## href ## &quot;telephone-numbers.htm&quot; ## href ## &quot;mailto:info@pulaskicounty.org&quot; ## href ## &quot;https://www.facebook.com/PulaskiVirginia&quot; ## href ## &quot;GIS.html&quot; ## href ## &quot;http://www.pclibs.org/&quot; ## href ## &quot;links.html&quot; ## href ## &quot;http://www.pcva.us/&quot; ## href ## &quot;http://www.dublintown.org/&quot; ## href ## &quot;http://www.pulaskitown.org/&quot; The above code downloads the html for the Board’s website and saves it in bosMainPage. The next line extracts all the links leading away from that page. It looks like a promising place to look is in the links such as ‘Board-of-Supervisors-Minutes-1992.html’. We can get just those links with the following: minutesLinks = grep(&quot;Minutes&quot;, links, value = T) fullMinutesUrl = paste0(&quot;http://www.pulaskicounty.org/&quot;, minutesLinks) fullMinutesUrl ## [1] &quot;http://www.pulaskicounty.org/Board-of-Supervisors-Minutes-2017.html&quot; ## [2] &quot;http://www.pulaskicounty.org/Board-of-Supervisors-Minutes-2016.html&quot; ## [3] &quot;http://www.pulaskicounty.org/Board-of-Supervisors-Minutes-2015.html&quot; ## [4] &quot;http://www.pulaskicounty.org/Board-of-Supervisors-Minutes-2014.html&quot; ## [5] &quot;http://www.pulaskicounty.org/Board-of-Supervisors-Minutes-2013.html&quot; ## [6] &quot;http://www.pulaskicounty.org/Board-of-Supervisors-Minutes-2012.html&quot; ## [7] &quot;http://www.pulaskicounty.org/Board-of-Supervisors-Minutes-2011.html&quot; ## [8] &quot;http://www.pulaskicounty.org/Board-of-Supervisors-Minutes-2010.html&quot; ## [9] &quot;http://www.pulaskicounty.org/Board-of-Supervisors-Minutes-2009.html&quot; ## [10] &quot;http://www.pulaskicounty.org/Board-of-Supervisors-Minutes-2008.html&quot; ## [11] &quot;http://www.pulaskicounty.org/Board-of-Supervisors-Minutes-2007.html&quot; ## [12] &quot;http://www.pulaskicounty.org/Board-of-Supervisors-Minutes-2006.html&quot; ## [13] &quot;http://www.pulaskicounty.org/Board-of-Supervisors-Minutes-2005.html&quot; ## [14] &quot;http://www.pulaskicounty.org/Board-of-Supervisors-Minutes-2004.html&quot; ## [15] &quot;http://www.pulaskicounty.org/Board-of-Supervisors-Minutes-2003.html&quot; ## [16] &quot;http://www.pulaskicounty.org/Board-of-Supervisors-Minutes-2002.html&quot; ## [17] &quot;http://www.pulaskicounty.org/Board-of-Supervisors-Minutes-2000.html&quot; ## [18] &quot;http://www.pulaskicounty.org/Board-of-Supervisors-Minutes-2001.html&quot; ## [19] &quot;http://www.pulaskicounty.org/Board-of-Supervisors-Minutes-1999.html&quot; ## [20] &quot;http://www.pulaskicounty.org/Board-of-Supervisors-Minutes-1998.html&quot; ## [21] &quot;http://www.pulaskicounty.org/Board-of-Supervisors-Minutes-1997.html&quot; ## [22] &quot;http://www.pulaskicounty.org/Board-of-Supervisors-Minutes-1996.html&quot; ## [23] &quot;http://www.pulaskicounty.org/Board-of-Supervisors-Minutes-1995.html&quot; ## [24] &quot;http://www.pulaskicounty.org/Board-of-Supervisors-Minutes-1994.html&quot; ## [25] &quot;http://www.pulaskicounty.org/Board-of-Supervisors-Minutes-1993.html&quot; ## [26] &quot;http://www.pulaskicounty.org/Board-of-Supervisors-Minutes-1992.html&quot; ## [27] &quot;http://www.pulaskicounty.org/Board-of-Supervisors-Minutes-1991.html&quot; The function grep is a base r function that returns strings which contain a pattern. We used it above to take all the urls on the main page and extract only the ones which contain ‘Minutes’, since those are the ones that contain links to the meeting minutes. Now we have all the urls to the pages where the minutes are kept. To work with all of them we could use a loop or an apply function, but we’ll just do one for illustration. We want to go to the page, find all the pdf’s with the minutes, and download them. A natural idea is to find everything with ‘.pdf’, but observe: minutePage2016 = htmlParse(fullMinutesUrl[2]) pdfLinks = grep(&quot;.pdf&quot;, xpathSApply(minutePage2016, &quot;//a/@href&quot;), value = T) pdfLinks ## href ## &quot;files/Churches.pdf&quot; ## href ## &quot;bos/Minutes and Agendas/2016/01 18 minutes organizational.pdf&quot; ## href ## &quot;bos/Minutes and Agendas/2016/01 25 minutes regular.pdf&quot; ## href ## &quot;bos/Minutes and Agendas/2016/02 16 minutes budget.pdf&quot; ## href ## &quot;bos/Minutes and Agendas/2016/02 22 minutes regular.pdf&quot; ## href ## &quot;bos/Minutes and Agendas/2016/02 26 minutes joint.pdf&quot; ## href ## &quot;bos/Minutes and Agendas/2016/02 29 minutes budget.pdf&quot; ## href ## &quot;bos/Minutes and Agendas/2016/03 07 minutes budget.pdf&quot; ## href ## &quot;bos/Minutes and Agendas/2016/03 14 minutes budget.pdf&quot; ## href ## &quot;bos/Minutes and Agendas/2016/03 21 minutes budget.pdf&quot; ## href ## &quot;bos/Minutes and Agendas/2016/03 28 minutes regular.pdf&quot; ## href ## &quot;bos/Minutes and Agendas/2016/03 31 minutes joint.pdf&quot; ## href ## &quot;bos/Minutes and Agendas/2016/04 04 minutes budget.pdf&quot; ## href ## &quot;bos/Minutes and Agendas/2016/04 11 minutes budget.pdf&quot; ## href ## &quot;bos/Minutes and Agendas/2016/04 25 minutes regular.pdf&quot; ## href ## &quot;bos/Minutes and Agendas/2016/05 02 minutes budget.pdf&quot; ## href ## &quot;bos/Minutes and Agendas/2016/05 23 minutes regular.pdf&quot; ## href ## &quot;bos/Minutes and Agendas/2016/07 25 minutes regular.pdf&quot; ## href ## &quot;bos/Minutes and Agendas/2016/08 02 minutes closed session.pdf&quot; ## href ## &quot;bos/Minutes and Agendas/2016/08 15 minutes closed session.pdf&quot; ## href ## &quot;bos/Minutes and Agendas/2016/08 22 minutes regular.pdf&quot; ## href ## &quot;bos/Minutes and Agendas/2016/09 07 minutes closed session.pdf&quot; ## href ## &quot;bos/Minutes and Agendas/2016/09 26 minutes regular.pdf&quot; ## href ## &quot;bos/Minutes and Agendas/2016/09 28 minutes closed session.pdf&quot; ## href ## &quot;bos/Minutes and Agendas/2016/10 14 minutes special.pdf&quot; ## href ## &quot;bos/Minutes and Agendas/2016/10 24 minutes regular.pdf&quot; ## href ## &quot;bos/Minutes and Agendas/2016/11 09 minutes electoral board.pdf&quot; ## href ## &quot;bos/Minutes and Agendas/2016/11 28 minutes regular.pdf&quot; ## href ## &quot;bos/Minutes and Agendas/2016/11 30 minutes closed session.pdf&quot; ## href ## &quot;files/Animal Control.pdf&quot; ## href ## &quot;files/Churches.pdf&quot; It’s always wise to make sure your expressions are getting you the things you want. Here, we have all the meeting pdfs, but also some extra page images. In this case, we can match like so: pdfLinks = grep(&quot;Minutes and Agendas&quot;, xpathSApply(minutePage2016, &quot;//a/@href&quot;), value = T) fullPdfUrl = paste0(&quot;http://www.pulaskicounty.org/&quot;, pdfLinks) fullPdfUrl ## [1] &quot;http://www.pulaskicounty.org/bos/Minutes and Agendas/2016/01 18 minutes organizational.pdf&quot; ## [2] &quot;http://www.pulaskicounty.org/bos/Minutes and Agendas/2016/01 25 minutes regular.pdf&quot; ## [3] &quot;http://www.pulaskicounty.org/bos/Minutes and Agendas/2016/02 16 minutes budget.pdf&quot; ## [4] &quot;http://www.pulaskicounty.org/bos/Minutes and Agendas/2016/02 22 minutes regular.pdf&quot; ## [5] &quot;http://www.pulaskicounty.org/bos/Minutes and Agendas/2016/02 26 minutes joint.pdf&quot; ## [6] &quot;http://www.pulaskicounty.org/bos/Minutes and Agendas/2016/02 29 minutes budget.pdf&quot; ## [7] &quot;http://www.pulaskicounty.org/bos/Minutes and Agendas/2016/03 07 minutes budget.pdf&quot; ## [8] &quot;http://www.pulaskicounty.org/bos/Minutes and Agendas/2016/03 14 minutes budget.pdf&quot; ## [9] &quot;http://www.pulaskicounty.org/bos/Minutes and Agendas/2016/03 21 minutes budget.pdf&quot; ## [10] &quot;http://www.pulaskicounty.org/bos/Minutes and Agendas/2016/03 28 minutes regular.pdf&quot; ## [11] &quot;http://www.pulaskicounty.org/bos/Minutes and Agendas/2016/03 31 minutes joint.pdf&quot; ## [12] &quot;http://www.pulaskicounty.org/bos/Minutes and Agendas/2016/04 04 minutes budget.pdf&quot; ## [13] &quot;http://www.pulaskicounty.org/bos/Minutes and Agendas/2016/04 11 minutes budget.pdf&quot; ## [14] &quot;http://www.pulaskicounty.org/bos/Minutes and Agendas/2016/04 25 minutes regular.pdf&quot; ## [15] &quot;http://www.pulaskicounty.org/bos/Minutes and Agendas/2016/05 02 minutes budget.pdf&quot; ## [16] &quot;http://www.pulaskicounty.org/bos/Minutes and Agendas/2016/05 23 minutes regular.pdf&quot; ## [17] &quot;http://www.pulaskicounty.org/bos/Minutes and Agendas/2016/07 25 minutes regular.pdf&quot; ## [18] &quot;http://www.pulaskicounty.org/bos/Minutes and Agendas/2016/08 02 minutes closed session.pdf&quot; ## [19] &quot;http://www.pulaskicounty.org/bos/Minutes and Agendas/2016/08 15 minutes closed session.pdf&quot; ## [20] &quot;http://www.pulaskicounty.org/bos/Minutes and Agendas/2016/08 22 minutes regular.pdf&quot; ## [21] &quot;http://www.pulaskicounty.org/bos/Minutes and Agendas/2016/09 07 minutes closed session.pdf&quot; ## [22] &quot;http://www.pulaskicounty.org/bos/Minutes and Agendas/2016/09 26 minutes regular.pdf&quot; ## [23] &quot;http://www.pulaskicounty.org/bos/Minutes and Agendas/2016/09 28 minutes closed session.pdf&quot; ## [24] &quot;http://www.pulaskicounty.org/bos/Minutes and Agendas/2016/10 14 minutes special.pdf&quot; ## [25] &quot;http://www.pulaskicounty.org/bos/Minutes and Agendas/2016/10 24 minutes regular.pdf&quot; ## [26] &quot;http://www.pulaskicounty.org/bos/Minutes and Agendas/2016/11 09 minutes electoral board.pdf&quot; ## [27] &quot;http://www.pulaskicounty.org/bos/Minutes and Agendas/2016/11 28 minutes regular.pdf&quot; ## [28] &quot;http://www.pulaskicounty.org/bos/Minutes and Agendas/2016/11 30 minutes closed session.pdf&quot; By looping through all the years above and combining the results, we can get a full list of all the urls for the Pulaski Board of Supervisors minutes pdfs. Then, it’s a simple application of a loop to go in and download them all for later work. 7.1.3 Lookaround Examples naicsAndCompanies = c(&quot;Name: Herbalife Ltd; NAICS: 325411, 325412, 424490&quot;, &quot;Name: Sanofi-Aventis SA; NAICS: 325412&quot;, &quot;Name: Abbott Laboratories; NAICS: 325411, 325412, 325413, 325620, 334516, 339112&quot;, &quot;Name: Alexion Pharmaceuticals Inc; NAICS: 325412&quot;, &quot;Name: Purdue Pharma LP; NAICS: 325412; Name: Transcept Pharmaceuticals Inc; NAICS: 325412&quot;, &quot;Name: Sanofi-Aventis SA; NAICS: 325412&quot;) naicsAndCompanies ## [1] &quot;Name: Herbalife Ltd; NAICS: 325411, 325412, 424490&quot; ## [2] &quot;Name: Sanofi-Aventis SA; NAICS: 325412&quot; ## [3] &quot;Name: Abbott Laboratories; NAICS: 325411, 325412, 325413, 325620, 334516, 339112&quot; ## [4] &quot;Name: Alexion Pharmaceuticals Inc; NAICS: 325412&quot; ## [5] &quot;Name: Purdue Pharma LP; NAICS: 325412; Name: Transcept Pharmaceuticals Inc; NAICS: 325412&quot; ## [6] &quot;Name: Sanofi-Aventis SA; NAICS: 325412&quot; We want a table with company names in one column and NAICS codes in another column. How can we extract the components we want? Let’s focus on the first entry for now. Notice that a semicolon separates the name from the NAICS codes. We can use that to split the string using lookarounds. (?=X) is the lookahead operator. It looks AHEAD for the pattern X; that is, it matches things that come BEFORE it (?&lt;=X) is the lookbehind operator. It looks BEHIND for the pattern X; that is, it matches things that come AFTER it (X) contains the pattern X that comes before the look ahead or after the lookbehind ‘.*’ means match the wildcard ‘.’ any number of times ’*’. firstRegexCase = naicsAndCompanies[[1]] firstRegexCase ## [1] &quot;Name: Herbalife Ltd; NAICS: 325411, 325412, 424490&quot; company = str_extract(firstRegexCase, &quot;(.*?)(?=;)&quot;) naicsCodes = str_extract(firstRegexCase, &quot;(?&lt;=NAICS: )(.*)&quot;) company ## [1] &quot;Name: Herbalife Ltd&quot; naicsCodes ## [1] &quot;325411, 325412, 424490&quot; We’re getting there, but not quite. We don’t want that annoying ‘Name:’ in front of the company. We can achieve that with the following. The lookbehind ‘(?&lt;=Name: )’ will find a place in the string that matches the pattern ‘Name:’ and then match what comes next, which in this case is anything (.*). cleanerCompany = str_extract(company, &quot;(?&lt;=Name: )(.*)&quot;) cleanerCompany ## [1] &quot;Herbalife Ltd&quot; Note that we could have removed the ‘Name:’ directly using a function called gsub, but the lookbehind will be useful later. gsub replaces the pattern in the first argument with the pattern in the second wherever it finds it in the third argument. gsub(&quot;Name: &quot;, &quot;&quot;, company) ## [1] &quot;Herbalife Ltd&quot; Now we can tackle the whole vector. We’ll use the same idea of separating names from codes using semicolons, but with two new challenges. naicsAndCompanies[[5]] ## [1] &quot;Name: Purdue Pharma LP; NAICS: 325412; Name: Transcept Pharmaceuticals Inc; NAICS: 325412&quot; This entry has multiple companies in the same line. To get at both of them, we need to use str_extract_all() instead of just str_extract(). str_extract_all(naicsAndCompanies, &quot;(?&lt;=Name: )(.*)(?=;)&quot;) ## [[1]] ## [1] &quot;Herbalife Ltd&quot; ## ## [[2]] ## [1] &quot;Sanofi-Aventis SA&quot; ## ## [[3]] ## [1] &quot;Abbott Laboratories&quot; ## ## [[4]] ## [1] &quot;Alexion Pharmaceuticals Inc&quot; ## ## [[5]] ## [1] &quot;Purdue Pharma LP; NAICS: 325412; Name: Transcept Pharmaceuticals Inc&quot; ## ## [[6]] ## [1] &quot;Sanofi-Aventis SA&quot; Whoops, looks like we didn’t split the 5th string at the right place! This is because the regular expression by default tries to match the longest string possible. This is called greedy matching. We can disable it by adding ‘?’ after the wild card companies = str_extract_all(naicsAndCompanies, &quot;(?&lt;=Name: )(.*?)(?=;)&quot;) companies ## [[1]] ## [1] &quot;Herbalife Ltd&quot; ## ## [[2]] ## [1] &quot;Sanofi-Aventis SA&quot; ## ## [[3]] ## [1] &quot;Abbott Laboratories&quot; ## ## [[4]] ## [1] &quot;Alexion Pharmaceuticals Inc&quot; ## ## [[5]] ## [1] &quot;Purdue Pharma LP&quot; &quot;Transcept Pharmaceuticals Inc&quot; ## ## [[6]] ## [1] &quot;Sanofi-Aventis SA&quot; Now let’s do the same for the NAICS codes. str_extract_all(paste0(naicsAndCompanies), &quot;(?&lt;=NAICS: )(.*?)(?=;)&quot;) ## [[1]] ## character(0) ## ## [[2]] ## character(0) ## ## [[3]] ## character(0) ## ## [[4]] ## character(0) ## ## [[5]] ## [1] &quot;325412&quot; ## ## [[6]] ## character(0) What’s going on here? This code looks for stuff between ‘NAICS:’ and ‘;’, but except for the 5th line there’s never a ‘;’ after ‘NAICS:’. To get around this, we can use a logical OR operator, along with a special symbol meaning ‘end of the string’. Here, the expression ‘(;|$)’ means ’match either ; OR the end of the line;. allNaics = str_extract_all(paste0(naicsAndCompanies), &quot;(?&lt;=NAICS: )(.*?)(?=(;|$))&quot;) allNaics ## [[1]] ## [1] &quot;325411, 325412, 424490&quot; ## ## [[2]] ## [1] &quot;325412&quot; ## ## [[3]] ## [1] &quot;325411, 325412, 325413, 325620, 334516, 339112&quot; ## ## [[4]] ## [1] &quot;325412&quot; ## ## [[5]] ## [1] &quot;325412&quot; &quot;325412&quot; ## ## [[6]] ## [1] &quot;325412&quot; Finally, we can put it all together and we have a clean company by naics table: companyNaicsList = data.frame(company = unlist(companies), naicsCodes = unlist(allNaics)) companyNaicsList ## company ## 1 Herbalife Ltd ## 2 Sanofi-Aventis SA ## 3 Abbott Laboratories ## 4 Alexion Pharmaceuticals Inc ## 5 Purdue Pharma LP ## 6 Transcept Pharmaceuticals Inc ## 7 Sanofi-Aventis SA ## naicsCodes ## 1 325411, 325412, 424490 ## 2 325412 ## 3 325411, 325412, 325413, 325620, 334516, 339112 ## 4 325412 ## 5 325412 ## 6 325412 ## 7 325412 "],
["factors.html", "Chapter 8 Factors", " Chapter 8 Factors Factors chapter in r4ds http://r4ds.had.co.nz/factors.html DataCamp Courses Resources http://forcats.tidyverse.org/ https://github.com/tidyverse/forcats "],
["forcats.html", "8.1 forcats", " 8.1 forcats library(forcats) library(dplyr) ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union library(ggplot2) x1 &lt;- c(&quot;M&quot;, &quot;T&quot;, &quot;W&quot;, &quot;R&quot;, &quot;F&quot;, &quot;S&quot;, &quot;U&quot;) x2 &lt;- c(&quot;Sa&quot;, &quot;Su&quot;) "],
["sorting.html", "8.2 Sorting", " 8.2 Sorting sort(x1) ## [1] &quot;F&quot; &quot;M&quot; &quot;R&quot; &quot;S&quot; &quot;T&quot; &quot;U&quot; &quot;W&quot; proper_order &lt;- x1 cat1 &lt;- factor(x1, levels = proper_order) cat1 ## [1] M T W R F S U ## Levels: M T W R F S U sort(cat1) ## [1] M T W R F S U ## Levels: M T W R F S U "],
["counting.html", "8.3 Counting", " 8.3 Counting head(gss_cat) ## # A tibble: 6 x 9 ## year marital age race rincome partyid relig denom tvhours ## &lt;int&gt; &lt;fct&gt; &lt;int&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;int&gt; ## 1 2000 Never married 26 White $8000 t… Ind,near… Prote… South… 12 ## 2 2000 Divorced 48 White $8000 t… Not str … Prote… Bapti… NA ## 3 2000 Widowed 67 White Not app… Independ… Prote… No de… 2 ## 4 2000 Never married 39 White Not app… Ind,near… Ortho… Not a… 4 ## 5 2000 Divorced 25 White Not app… Not str … None Not a… 1 ## 6 2000 Married 25 White $20000 … Strong d… Prote… South… NA dplyr::count(gss_cat, marital) ## # A tibble: 6 x 2 ## marital n ## &lt;fct&gt; &lt;int&gt; ## 1 No answer 17 ## 2 Never married 5416 ## 3 Separated 743 ## 4 Divorced 3383 ## 5 Widowed 1807 ## 6 Married 10117 gss_cat %&gt;% dplyr::count(marital) ## # A tibble: 6 x 2 ## marital n ## &lt;fct&gt; &lt;int&gt; ## 1 No answer 17 ## 2 Never married 5416 ## 3 Separated 743 ## 4 Divorced 3383 ## 5 Widowed 1807 ## 6 Married 10117 "],
["re-ording-factors.html", "8.4 Re-ording factors", " 8.4 Re-ording factors library(ggplot2) library(dplyr) relig_summary &lt;- gss_cat %&gt;% dplyr::group_by(relig) %&gt;% dplyr::summarize( tvhours = mean(tvhours, na.rm = TRUE), age = mean(age, na.rm = TRUE), n = n() ) relig_summary ## # A tibble: 15 x 4 ## relig tvhours age n ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 No answer 2.72 49.5 93 ## 2 Don&#39;t know 4.62 35.9 15 ## 3 Inter-nondenominational 2.87 40.0 109 ## 4 Native american 3.46 38.9 23 ## 5 Christian 2.79 40.1 689 ## 6 Orthodox-christian 2.42 50.4 95 ## 7 Moslem/islam 2.44 37.6 104 ## 8 Other eastern 1.67 45.9 32 ## 9 Hinduism 1.89 37.7 71 ## 10 Buddhism 2.38 44.7 147 ## 11 Other 2.73 41.0 224 ## 12 None 2.71 41.2 3523 ## 13 Jewish 2.52 52.4 388 ## 14 Catholic 2.96 46.9 5124 ## 15 Protestant 3.15 49.9 10846 ggplot(relig_summary, aes(x = tvhours, y = relig)) + geom_point() ggplot(relig_summary, aes(x = tvhours, y = fct_reorder(relig, tvhours))) + geom_point() "],
["modifying-factor-values.html", "8.5 Modifying factor values", " 8.5 Modifying factor values gss_cat %&gt;% count(partyid) ## # A tibble: 10 x 2 ## partyid n ## &lt;fct&gt; &lt;int&gt; ## 1 No answer 154 ## 2 Don&#39;t know 1 ## 3 Other party 393 ## 4 Strong republican 2314 ## 5 Not str republican 3032 ## 6 Ind,near rep 1791 ## 7 Independent 4119 ## 8 Ind,near dem 2499 ## 9 Not str democrat 3690 ## 10 Strong democrat 3490 # same as below #forcats::fct_recode(gss_cat$partyid) forcats::fct_recode(gss_cat$partyid, &quot;Rep, Strong&quot; = &quot;Strong republican&quot;, &quot;Dem, Strong&quot; = &quot;Strong democrat&quot;) %&gt;% head(30) ## [1] Ind,near rep Not str republican Independent ## [4] Ind,near rep Not str democrat Dem, Strong ## [7] Not str republican Ind,near dem Not str democrat ## [10] Rep, Strong Not str democrat Ind,near rep ## [13] Dem, Strong Rep, Strong Ind,near dem ## [16] Dem, Strong Rep, Strong Independent ## [19] Not str democrat Independent Ind,near dem ## [22] Rep, Strong Independent Ind,near rep ## [25] Not str democrat Dem, Strong Not str democrat ## [28] Rep, Strong Dem, Strong Independent ## 10 Levels: No answer Don&#39;t know Other party ... Dem, Strong gss_cat_recoded &lt;- gss_cat %&gt;% mutate(party_id_recode = fct_recode( partyid, &quot;Rep, Strong&quot; = &quot;Strong republican&quot;, &quot;Dem, Strong&quot; = &quot;Strong democrat&quot;)) 8.5.1 Double check your work https://gist.github.com/jennybc/04b71bfaaf0f88d9d2eb # do a cross tab in R table(gss_cat_recoded$partyid, gss_cat_recoded$party_id_recode, useNA = &#39;always&#39;) ## ## No answer Don&#39;t know Other party Rep, Strong ## No answer 154 0 0 0 ## Don&#39;t know 0 1 0 0 ## Other party 0 0 393 0 ## Strong republican 0 0 0 2314 ## Not str republican 0 0 0 0 ## Ind,near rep 0 0 0 0 ## Independent 0 0 0 0 ## Ind,near dem 0 0 0 0 ## Not str democrat 0 0 0 0 ## Strong democrat 0 0 0 0 ## &lt;NA&gt; 0 0 0 0 ## ## Not str republican Ind,near rep Independent ## No answer 0 0 0 ## Don&#39;t know 0 0 0 ## Other party 0 0 0 ## Strong republican 0 0 0 ## Not str republican 3032 0 0 ## Ind,near rep 0 1791 0 ## Independent 0 0 4119 ## Ind,near dem 0 0 0 ## Not str democrat 0 0 0 ## Strong democrat 0 0 0 ## &lt;NA&gt; 0 0 0 ## ## Ind,near dem Not str democrat Dem, Strong &lt;NA&gt; ## No answer 0 0 0 0 ## Don&#39;t know 0 0 0 0 ## Other party 0 0 0 0 ## Strong republican 0 0 0 0 ## Not str republican 0 0 0 0 ## Ind,near rep 0 0 0 0 ## Independent 0 0 0 0 ## Ind,near dem 2499 0 0 0 ## Not str democrat 0 3690 0 0 ## Strong democrat 0 0 3490 0 ## &lt;NA&gt; 0 0 0 0 "],
["dates-and-times.html", "Chapter 9 Dates and Times", " Chapter 9 Dates and Times Resources http://lubridate.tidyverse.org/ https://github.com/tidyverse/lubridate Cheat Sheets https://rawgit.com/rstudio/cheatsheets/master/lubridate.pdf "],
["lubridate.html", "9.1 lubridate", " 9.1 lubridate library(lubridate) ## ## Attaching package: &#39;lubridate&#39; ## The following object is masked from &#39;package:base&#39;: ## ## date ymd(&#39;2018-06-06&#39;) ## [1] &quot;2018-06-06&quot; dt_str &lt;- &#39;2018-06-06&#39; class(dt_str) ## [1] &quot;character&quot; dt_dt &lt;- ymd(dt_str) class(dt_dt) ## [1] &quot;Date&quot; mdy(&#39;June 6, 2018&#39;) ## [1] &quot;2018-06-06&quot; dmy(&#39;06-06-2018&#39;) ## [1] &quot;2018-06-06&quot; ymd(20190606) ## [1] &quot;2019-06-06&quot; ymd_hms(&#39;2018-06-06 10:33:55&#39;, tz = &#39;EDT&#39;) ## [1] &quot;2018-06-06 14:33:55 EDT&quot; "],
["making-datetimes-from-data.html", "9.2 Making datetimes from data", " 9.2 Making datetimes from data library(nycflights13) library(dplyr) ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:lubridate&#39;: ## ## intersect, setdiff, union ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union flights ## # A tibble: 336,776 x 19 ## year month day dep_time sched_dep_time dep_delay arr_time ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; ## 1 2013 1 1 517 515 2 830 ## 2 2013 1 1 533 529 4 850 ## 3 2013 1 1 542 540 2 923 ## 4 2013 1 1 544 545 -1 1004 ## 5 2013 1 1 554 600 -6 812 ## 6 2013 1 1 554 558 -4 740 ## 7 2013 1 1 555 600 -5 913 ## 8 2013 1 1 557 600 -3 709 ## 9 2013 1 1 557 600 -3 838 ## 10 2013 1 1 558 600 -2 753 ## # ... with 336,766 more rows, and 12 more variables: sched_arr_time &lt;int&gt;, ## # arr_delay &lt;dbl&gt;, carrier &lt;chr&gt;, flight &lt;int&gt;, tailnum &lt;chr&gt;, ## # origin &lt;chr&gt;, dest &lt;chr&gt;, air_time &lt;dbl&gt;, distance &lt;dbl&gt;, hour &lt;dbl&gt;, ## # minute &lt;dbl&gt;, time_hour &lt;dttm&gt; flight_times &lt;- flights %&gt;% select(year, month, day, hour, minute) flight_times ## # A tibble: 336,776 x 5 ## year month day hour minute ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2013 1 1 5 15 ## 2 2013 1 1 5 29 ## 3 2013 1 1 5 40 ## 4 2013 1 1 5 45 ## 5 2013 1 1 6 0 ## 6 2013 1 1 5 58 ## 7 2013 1 1 6 0 ## 8 2013 1 1 6 0 ## 9 2013 1 1 6 0 ## 10 2013 1 1 6 0 ## # ... with 336,766 more rows flight_times %&gt;% mutate(dep_dt = make_datetime(year, month, day, hour, minute)) ## # A tibble: 336,776 x 6 ## year month day hour minute dep_dt ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dttm&gt; ## 1 2013 1 1 5 15 2013-01-01 05:15:00 ## 2 2013 1 1 5 29 2013-01-01 05:29:00 ## 3 2013 1 1 5 40 2013-01-01 05:40:00 ## 4 2013 1 1 5 45 2013-01-01 05:45:00 ## 5 2013 1 1 6 0 2013-01-01 06:00:00 ## 6 2013 1 1 5 58 2013-01-01 05:58:00 ## 7 2013 1 1 6 0 2013-01-01 06:00:00 ## 8 2013 1 1 6 0 2013-01-01 06:00:00 ## 9 2013 1 1 6 0 2013-01-01 06:00:00 ## 10 2013 1 1 6 0 2013-01-01 06:00:00 ## # ... with 336,766 more rows flights %&gt;% select(year, month, day, hour, minute) %&gt;% mutate(dep_dt = make_datetime(year, month, day, hour, minute)) ## # A tibble: 336,776 x 6 ## year month day hour minute dep_dt ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dttm&gt; ## 1 2013 1 1 5 15 2013-01-01 05:15:00 ## 2 2013 1 1 5 29 2013-01-01 05:29:00 ## 3 2013 1 1 5 40 2013-01-01 05:40:00 ## 4 2013 1 1 5 45 2013-01-01 05:45:00 ## 5 2013 1 1 6 0 2013-01-01 06:00:00 ## 6 2013 1 1 5 58 2013-01-01 05:58:00 ## 7 2013 1 1 6 0 2013-01-01 06:00:00 ## 8 2013 1 1 6 0 2013-01-01 06:00:00 ## 9 2013 1 1 6 0 2013-01-01 06:00:00 ## 10 2013 1 1 6 0 2013-01-01 06:00:00 ## # ... with 336,766 more rows "],
["non-standard-date-formatting.html", "9.3 Non-standard date formatting", " 9.3 Non-standard date formatting # an example of a non-standard date format &#39;WED 06-JUNE-18 10:47:30 AM&#39; ## [1] &quot;WED 06-JUNE-18 10:47:30 AM&quot; If you look at the as_datetime function, under the ‘format’ section there is a link to the strptime documentation ?lubridate::as_datetime If you look at the strptime documentation, you will get a nice table of codes you can use to create your own datetime pattern ?strptime You can now use these variables to create a pattern for your custom datetime string curr_time &lt;- lubridate::as_datetime(&#39;WED 06-JUNE-18 10:47:30 AM&#39;, format = &#39;%a %d-%B-%y %I:%M:%S %p&#39;, tz = &quot;EST&quot;) curr_time ## [1] &quot;2018-06-06 10:47:30 EST&quot; "],
["strptime-format-variables.html", "9.4 strptime format variables", " 9.4 strptime format variables The table of values in strptime have been reproduced below %a Abbreviated weekday name in the current locale on this platform. (Also matches full name on input: in some locales there are no abbreviations of names.) %A Full weekday name in the current locale. (Also matches abbreviated name on input.) %b Abbreviated month name in the current locale on this platform. (Also matches full name on input: in some locales there are no abbreviations of names.) %B Full month name in the current locale. (Also matches abbreviated name on input.) %c Date and time. Locale-specific on output, &quot;%a %b %e %H:%M:%S %Y&quot; on input. %C Century (00–99): the integer part of the year divided by 100. %d Day of the month as decimal number (01–31). %D Date format such as %m/%d/%y: the C99 standard says it should be that exact format (but not all OSes comply). %e Day of the month as decimal number (1–31), with a leading space for a single-digit number. %F Equivalent to %Y-%m-%d (the ISO 8601 date format). %g The last two digits of the week-based year (see %V). (Accepted but ignored on input.) %G The week-based year (see %V) as a decimal number. (Accepted but ignored on input.) %h Equivalent to %b. %H Hours as decimal number (00–23). As a special exception strings such as 24:00:00 are accepted for input, since ISO 8601 allows these. %I Hours as decimal number (01–12). %j Day of year as decimal number (001–366). %m Month as decimal number (01–12). %M Minute as decimal number (00–59). %n Newline on output, arbitrary whitespace on input. %p AM/PM indicator in the locale. Used in conjunction with %I and not with %H. An empty string in some locales (for example on some OSes, non-English European locales including Russia). The behaviour is undefined if used for input in such a locale. Some platforms accept %P for output, which uses a lower-case version (%p may also use lower case): others will output P. %r For output, the 12-hour clock time (using the locale&#39;s AM or PM): only defined in some locales, and on some OSes misleading in locales which do not define an AM/PM indicator. For input, equivalent to %I:%M:%S %p. %R Equivalent to %H:%M. %S Second as integer (00–61), allowing for up to two leap-seconds (but POSIX-compliant implementations will ignore leap seconds). %t Tab on output, arbitrary whitespace on input. %T Equivalent to %H:%M:%S. %u Weekday as a decimal number (1–7, Monday is 1). %U Week of the year as decimal number (00–53) using Sunday as the first day 1 of the week (and typically with the first Sunday of the year as day 1 of week 1). The US convention. %V Week of the year as decimal number (01–53) as defined in ISO 8601. If the week (starting on Monday) containing 1 January has four or more days in the new year, then it is considered week 1. Otherwise, it is the last week of the previous year, and the next week is week 1. (Accepted but ignored on input.) %w Weekday as decimal number (0–6, Sunday is 0). %W Week of the year as decimal number (00–53) using Monday as the first day of week (and typically with the first Monday of the year as day 1 of week 1). The UK convention. %x Date. Locale-specific on output, &quot;%y/%m/%d&quot; on input. %X Time. Locale-specific on output, &quot;%H:%M:%S&quot; on input. %y Year without century (00–99). On input, values 00 to 68 are prefixed by 20 and 69 to 99 by 19 – that is the behaviour specified by the 2004 and 2008 POSIX standards, but they do also say ‘it is expected that in a future version the default century inferred from a 2-digit year will change’. %Y Year with century. Note that whereas there was no zero in the original Gregorian calendar, ISO 8601:2004 defines it to be valid (interpreted as 1BC): see https://en.wikipedia.org/wiki/0_(year). Note that the standards also say that years before 1582 in its calendar should only be used with agreement of the parties involved. For input, only years 0:9999 are accepted. %z Signed offset in hours and minutes from UTC, so -0800 is 8 hours behind UTC. Values up to +1400 are accepted. (Standard only for output.) %Z (Output only.) Time zone abbreviation as a character string (empty if not available). This may not be reliable when a time zone has changed abbreviations over the years. "],
["datetime-arithmetic.html", "9.5 Datetime arithmetic", " 9.5 Datetime arithmetic Once you have a datetime object, you can then begin to do calculations and arithmetic on them. now() - curr_time ## Time difference of 9.007128 days "],
["sql-databases.html", "Chapter 10 SQL Databases", " Chapter 10 SQL Databases R4ds chapter (relational data): http://r4ds.had.co.nz/relational-data.html Software-Carpentry SQL Lesson http://swcarpentry.github.io/sql-novice-survey/ DataCamp Courses https://www.datacamp.com/courses/intro-to-sql-for-data-science https://www.datacamp.com/courses/joining-data-in-postgresql "],
["databases-in-r.html", "10.1 Databases in R", " 10.1 Databases in R rap_chart_artists &lt;- readxl::read_excel(&quot;data/Rap_Charts.xlsx&quot;, sheet = &quot;Artists&quot;) rap_chart_singles &lt;- readxl::read_excel(&quot;data/Rap_Charts.xlsx&quot;, sheet = &quot;Singles&quot;) head(rap_chart_artists) ## # A tibble: 4 x 4 ## Artist_ID First_Name Last_Name Psuedonym ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 4 O&#39;Shea Jackson Ice Cube ## 2 3 Marvin Young Young M.C. ## 3 2 Stanley Burrell M.C. Hammer ## 4 1 James Smith LL Cool J head(rap_chart_singles) ## # A tibble: 6 x 5 ## Artist_ID Year Single Top_US_Rap_Chart Album ## &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 1 1984 &quot;\\&quot;I Need a Beat\\&quot;&quot; NA Non-album s… ## 2 1 1985 &quot;\\&quot;I Can&#39;t Live Without M… NA Radio ## 3 1 1986 &quot;\\&quot;Rock the Bells\\&quot;&quot; NA Radio ## 4 1 1986 &quot;\\&quot;I Can Give You More\\&quot;&quot; NA Radio ## 5 1 1986 &quot;\\&quot;You&#39;ll Rock\\&quot;&quot; NA Radio ## 6 1 1987 &quot;\\&quot;I&#39;m Bad\\&quot;&quot; NA Bigger and … 10.1.1 CREATE REUSABLE CONNECTION TO DATABASE # by default this will open up your own database (e.g., aschroed) my_db_con &lt;- sdalr::con_db(pass = sdalr::get_my_password()) 10.1.2 WRITE DATA TO DATABASE TABLES DBI::dbWriteTable(my_db_con, &quot;rap_chart_artists&quot;, rap_chart_artists, row.names = FALSE) DBI::dbWriteTable(my_db_con, &quot;rap_chart_singles&quot;, rap_chart_singles, row.names = FALSE) "],
["joins.html", "10.2 Joins", " 10.2 Joins 10.2.1 JOIN TABLES IN SQL WITH DBI DBI::dbGetQuery(my_db_con, &quot;SELECT * FROM rap_chart_artists a JOIN rap_chart_singles b ON a.\\&quot;Artist_ID\\&quot; = b.\\&quot;Artist_ID\\&quot;&quot;) 10.2.2 JOIN TABLES IN SQL IN SQL CHUNK ```{sql connection=my_db_con} SELECT * FROM rap_chart_artists a JOIN rap_chart_singles s ON a.\"Artist_ID\" = s.\"Artist_ID\" ``` 10.2.3 JOIN TABLES IN SQL IN SQL CHUNK WITH OUTPUT VARIABLE ```{sql connection=my_db_con, output.var=\"rap_artist_singles\"} SELECT * FROM rap_chart_artists a JOIN rap_chart_singles s ON a.\"Artist_ID\" = s.\"Artist_ID\" ``` rap_artist_singles[, c(&quot;First_Name&quot;, &quot;Last_Name&quot;)] 10.2.4 JOIN TABLES IN SQL IN SQL CHUNK APPLY WHERE CLAUSE AND FUZZY SEARCH ```{sql connection=my_db_con} SELECT * FROM rap_chart_artists a JOIN rap_chart_singles s ON a.\"Artist_ID\" = s.\"Artist_ID\" WHERE \"Psuedonym\" LIKE '%LL%' ``` 10.2.5 JOIN TABLES IN SQL IN SQL CHUNK APPLY WHERE CLAUSE WITH ‘AND’ AND FUZZY SEARCH ```{sql connection=my_db_con} SELECT * FROM rap_chart_artists a JOIN rap_chart_singles s ON a.\"Artist_ID\" = s.\"Artist_ID\" WHERE \"Psuedonym\" LIKE '%LL%' AND \"Top_US_Rap_Chart\" IS NOT NULL ``` 10.2.6 JOIN TABLES IN SQL IN SQL CHUNK APPLY SELECT AND WHERE CLAUSE WITH ‘AND’ AND FUZZY SEARCH AND ORDER ```{sql connection=my_db_con} SELECT \"Psuedonym\", \"Single\", \"Year\", \"Top_US_Rap_Chart\" FROM rap_chart_artists a JOIN rap_chart_singles s ON a.\"Artist_ID\" = s.\"Artist_ID\" WHERE \"Psuedonym\" LIKE '%LL%' AND \"Top_US_Rap_Chart\" IS NOT NULL ORDER BY \"Top_US_Rap_Chart\", \"Year\" ``` 10.2.7 JOIN TABLES IN SQL IN SQL CHUNK APPLY SELECT AND WHERE CLAUSE AND FUZZY SEARCH AND ORDER AND GROUP BY WITH AGGREGATE FUNCTION ```{sql connection=my_db_con, max.print = 15} SELECT \"Psuedonym\", \"Top_US_Rap_Chart\", COUNT(\"Top_US_Rap_Chart\") chart_position_cnt FROM rap_chart_artists a JOIN rap_chart_singles s ON a.\"Artist_ID\" = s.\"Artist_ID\" WHERE \"Psuedonym\" LIKE '%M.C.%' AND \"Top_US_Rap_Chart\" IS NOT NULL GROUP BY \"Psuedonym\", \"Top_US_Rap_Chart\" ORDER BY \"Psuedonym\", \"Top_US_Rap_Chart\" ``` "],
["dplyr-and-data-table.html", "10.3 dplyr and data.table", " 10.3 dplyr and data.table library(dplyr) ## ## Attaching package: &#39;dplyr&#39; ## The following objects are masked from &#39;package:stats&#39;: ## ## filter, lag ## The following objects are masked from &#39;package:base&#39;: ## ## intersect, setdiff, setequal, union library(data.table) ## ## Attaching package: &#39;data.table&#39; ## The following objects are masked from &#39;package:dplyr&#39;: ## ## between, first, last rap_chart_artists &lt;- readxl::read_excel(&quot;data/Rap_Charts.xlsx&quot;, sheet = &quot;Artists&quot;) rap_chart_singles &lt;- readxl::read_excel(&quot;data/Rap_Charts.xlsx&quot;, sheet = &quot;Singles&quot;) (rap_artist_singles &lt;- rap_chart_artists %&gt;% dplyr::full_join(rap_chart_singles, by = &quot;Artist_ID&quot;)) ## # A tibble: 167 x 8 ## Artist_ID First_Name Last_Name Psuedonym Year Single Top_US_Rap_Chart ## &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 4 O&#39;Shea Jackson Ice Cube 1990 &quot;\\&quot;Who… NA ## 2 4 O&#39;Shea Jackson Ice Cube 1990 &quot;\\&quot;Ame… 1 ## 3 4 O&#39;Shea Jackson Ice Cube 1990 &quot;\\&quot;End… NA ## 4 4 O&#39;Shea Jackson Ice Cube 1990 &quot;\\&quot;Dea… NA ## 5 4 O&#39;Shea Jackson Ice Cube 1990 &quot;\\&quot;Jac… NA ## 6 4 O&#39;Shea Jackson Ice Cube 1991 &quot;\\&quot;Ste… 3 ## 7 4 O&#39;Shea Jackson Ice Cube 1992 &quot;\\&quot;Tru… NA ## 8 4 O&#39;Shea Jackson Ice Cube 1992 &quot;\\&quot;Wic… NA ## 9 4 O&#39;Shea Jackson Ice Cube 1993 &quot;\\&quot;It … 1 ## 10 4 O&#39;Shea Jackson Ice Cube 1993 &quot;\\&quot;Che… 1 ## # ... with 157 more rows, and 1 more variable: Album &lt;chr&gt; rap_artist_singles_dt &lt;- setDT(rap_artist_singles) rap_artist_singles_dt[Psuedonym %like% &quot;LL&quot;] ## Artist_ID First_Name Last_Name Psuedonym Year ## 1: 1 James Smith LL Cool J 1984 ## 2: 1 James Smith LL Cool J 1985 ## 3: 1 James Smith LL Cool J 1986 ## 4: 1 James Smith LL Cool J 1986 ## 5: 1 James Smith LL Cool J 1986 ## 6: 1 James Smith LL Cool J 1987 ## 7: 1 James Smith LL Cool J 1987 ## 8: 1 James Smith LL Cool J 1987 ## 9: 1 James Smith LL Cool J 1988 ## 10: 1 James Smith LL Cool J 1989 ## 11: 1 James Smith LL Cool J 1989 ## 12: 1 James Smith LL Cool J 1989 ## 13: 1 James Smith LL Cool J 1990 ## 14: 1 James Smith LL Cool J 1990 ## 15: 1 James Smith LL Cool J 1990 ## 16: 1 James Smith LL Cool J 1990 ## 17: 1 James Smith LL Cool J 1991 ## 18: 1 James Smith LL Cool J 1991 ## 19: 1 James Smith LL Cool J 1991 ## 20: 1 James Smith LL Cool J 1991 ## 21: 1 James Smith LL Cool J 1991 ## 22: 1 James Smith LL Cool J 1993 ## 23: 1 James Smith LL Cool J 1993 ## 24: 1 James Smith LL Cool J 1993 ## 25: 1 James Smith LL Cool J 1993 ## 26: 1 James Smith LL Cool J 1995 ## 27: 1 James Smith LL Cool J 1996 ## 28: 1 James Smith LL Cool J 1996 ## 29: 1 James Smith LL Cool J 1996 ## 30: 1 James Smith LL Cool J 1997 ## 31: 1 James Smith LL Cool J 1997 ## 32: 1 James Smith LL Cool J 1997 ## 33: 1 James Smith LL Cool J 1998 ## 34: 1 James Smith LL Cool J 1998 ## 35: 1 James Smith LL Cool J 1998 ## 36: 1 James Smith LL Cool J 1999 ## 37: 1 James Smith LL Cool J 2000 ## 38: 1 James Smith LL Cool J 2000 ## 39: 1 James Smith LL Cool J 2000 ## 40: 1 James Smith LL Cool J 2000 ## 41: 1 James Smith LL Cool J 2002 ## 42: 1 James Smith LL Cool J 2003 ## 43: 1 James Smith LL Cool J 2003 ## 44: 1 James Smith LL Cool J 2004 ## 45: 1 James Smith LL Cool J 2005 ## 46: 1 James Smith LL Cool J 2006 ## 47: 1 James Smith LL Cool J 2006 ## 48: 1 James Smith LL Cool J 2006 ## 49: 1 James Smith LL Cool J 2008 ## 50: 1 James Smith LL Cool J 2008 ## 51: 1 James Smith LL Cool J 2009 ## 52: 1 James Smith LL Cool J 2011 ## 53: 1 James Smith LL Cool J 2012 ## 54: 1 James Smith LL Cool J 2012 ## 55: 1 James Smith LL Cool J 2013 ## 56: 1 James Smith LL Cool J 2013 ## 57: 1 James Smith LL Cool J 2013 ## 58: 1 James Smith LL Cool J 2013 ## 59: 1 James Smith LL Cool J 2014 ## 60: 1 James Smith LL Cool J 2016 ## Artist_ID First_Name Last_Name Psuedonym Year ## Single ## 1: &quot;I Need a Beat&quot; ## 2: &quot;I Can&#39;t Live Without My Radio&quot; ## 3: &quot;Rock the Bells&quot; ## 4: &quot;I Can Give You More&quot; ## 5: &quot;You&#39;ll Rock&quot; ## 6: &quot;I&#39;m Bad&quot; ## 7: &quot;I Need Love&quot; ## 8: &quot;Go Cut Creator Go&quot; ## 9: &quot;Going Back to Cali&quot; ## 10: &quot;I&#39;m That Type of Guy&quot; ## 11: &quot;Big Ole Butt&quot; ## 12: &quot;One Shot at Love&quot; ## 13: &quot;Jingling Baby&quot; ## 14: &quot;To da Break of Dawn&quot; ## 15: &quot;The Boomin&#39; System&quot; ## 16: &quot;Around the Way Girl&quot; ## 17: &quot;Mama Said Knock You Out&quot; ## 18: &quot;Around the Way Girl&quot; (remix) ## 19: &quot;6 Minutes of Pleasure&quot; ## 20: &quot;Who&#39;s Afraid of the Big Bad Wolf?&quot; ## 21: &quot;Strictly Business&quot; ## 22: &quot;How I&#39;m Comin&#39;&quot; ## 23: &quot;Back Seat (Of My Jeep)&quot; ## 24: &quot;Pink Cookies In a Plastic Bag Getting Crushed by Buildings&quot; ## 25: &quot;Stand By Your Man&quot; ## 26: &quot;Hey Lover&quot; (featuring Boyz II Men) ## 27: &quot;Doin&#39; It&quot; (featuring LeShaun) ## 28: &quot;Loungin&quot; (featuring Total) ## 29: &quot;Ain&#39;t Nobody&quot; ## 30: &quot;Hit &#39;Em High (The Monstars&#39; Anthem)&quot; (with B-Real, Busta Rhymes, Coolio and Method Man) ## 31: &quot;Phenomenon&quot; ## 32: &quot;4, 3, 2, 1&quot; (featuring Method Man, Redman, Canibusand DMX) ## 33: &quot;Father&quot; ## 34: &quot;Hot Hot Hot&quot; ## 35: &quot;Zoom&quot; (with Dr. Dre) ## 36: &quot;Deepest Bluest&quot; ## 37: &quot;Imagine That&quot; ## 38: &quot;Take it Off&quot; ## 39: &quot;You and Me&quot; (featuring Kelly Price) ## 40: &quot;Shut &#39;Em Down&quot; ## 41: &quot;Luv U Better&quot; ## 42: &quot;Paradise&quot; (featuring Ameriie) ## 43: &quot;Amazin&#39;&quot; ## 44: &quot;Headsprung&quot; ## 45: &quot;Hush&quot; (featuring 7 Aurelius) ## 46: &quot;It&#39;s LL and Santana&quot; (featuring Juelz Santana) ## 47: &quot;Control Myself&quot; (featuring Jennifer Lopez) ## 48: &quot;Freeze&quot; (featuring Lyfe Jennings) ## 49: &quot;Cry&quot; (featuring Lil&#39; Mo) ## 50: &quot;Baby&quot; (featuring The-Dream) ## 51: &quot;NCIS: No Crew Is Superior&quot; ## 52: &quot;No More&quot; (featuring Ne-Yo) ## 53: &quot;Ratchet&quot; ## 54: &quot;Take It&quot; (featuring Joe) ## 55: &quot;Whaddup&quot; (featuring Chuck D, Travis Barker, Tom Morello and DJ Z-Trip) ## 56: &quot;We Came to Party&quot; (featuring Snoop Dogg andFatman Scoop) ## 57: &quot;Live for You&quot; (featuring Brad Paisley) ## 58: &quot;Not Leaving You Tonight&quot; (featuring Fitz &amp; The Tantrums with Eddie Van Halen) ## 59: &quot;The Hustler&quot; (featuring Mavado) ## 60: &quot;You Already&quot; (featuring Troy Ave) ## Single ## Top_US_Rap_Chart Album ## 1: NA Non-album single ## 2: NA Radio ## 3: NA Radio ## 4: NA Radio ## 5: NA Radio ## 6: NA Bigger and Deffer ## 7: NA Bigger and Deffer ## 8: NA Bigger and Deffer ## 9: NA Walking with a Panther ## 10: 1 Walking with a Panther ## 11: 13 Walking with a Panther ## 12: NA Walking with a Panther ## 13: 6 Walking with a Panther ## 14: 17 Mama Said Knock You Out ## 15: 1 Mama Said Knock You Out ## 16: 1 Mama Said Knock You Out ## 17: 1 Mama Said Knock You Out ## 18: NA Mama Said Knock You Out ## 19: 7 Mama Said Knock You Out ## 20: NA Simply Mad About the Mouse ## 21: NA Strictly Business soundtrack ## 22: 1 14 Shots to the Dome ## 23: 2 14 Shots to the Dome ## 24: NA 14 Shots to the Dome ## 25: 24 14 Shots to the Dome ## 26: 1 Mr. Smith ## 27: 2 Mr. Smith ## 28: 1 Mr. Smith ## 29: 23 Beavis and Butt-Head Do America soundtrack ## 30: NA Space Jam soundtrack ## 31: 14 Phenomenon ## 32: 10 Phenomenon ## 33: 1 Phenomenon ## 34: NA Phenomenon ## 35: NA Bulworth soundtrack ## 36: NA Deep Blue Sea soundtrack ## 37: 16 G.O.A.T. ## 38: 35 G.O.A.T. ## 39: 44 G.O.A.T. ## 40: 31 Any Given Sunday soundtrack ## 41: 2 10 ## 42: 10 10 ## 43: NA 10 ## 44: 4 The DEFinition ## 45: 11 The DEFinition ## 46: NA Todd Smith ## 47: 9 Todd Smith ## 48: NA Todd Smith ## 49: NA Exit 13 ## 50: 10 Exit 13 ## 51: NA Non-album single ## 52: NA Non-album single ## 53: NA Non-album single ## 54: NA Authentic ## 55: NA Authentic ## 56: NA Authentic ## 57: NA Authentic ## 58: NA Authentic ## 59: NA G.O.A.T. 2 ## 60: NA TBA ## Top_US_Rap_Chart Album rap_artist_singles_dt[Psuedonym %like% &quot;LL&quot;, .(Psuedonym, Single, Top_US_Rap_Chart)] ## Psuedonym ## 1: LL Cool J ## 2: LL Cool J ## 3: LL Cool J ## 4: LL Cool J ## 5: LL Cool J ## 6: LL Cool J ## 7: LL Cool J ## 8: LL Cool J ## 9: LL Cool J ## 10: LL Cool J ## 11: LL Cool J ## 12: LL Cool J ## 13: LL Cool J ## 14: LL Cool J ## 15: LL Cool J ## 16: LL Cool J ## 17: LL Cool J ## 18: LL Cool J ## 19: LL Cool J ## 20: LL Cool J ## 21: LL Cool J ## 22: LL Cool J ## 23: LL Cool J ## 24: LL Cool J ## 25: LL Cool J ## 26: LL Cool J ## 27: LL Cool J ## 28: LL Cool J ## 29: LL Cool J ## 30: LL Cool J ## 31: LL Cool J ## 32: LL Cool J ## 33: LL Cool J ## 34: LL Cool J ## 35: LL Cool J ## 36: LL Cool J ## 37: LL Cool J ## 38: LL Cool J ## 39: LL Cool J ## 40: LL Cool J ## 41: LL Cool J ## 42: LL Cool J ## 43: LL Cool J ## 44: LL Cool J ## 45: LL Cool J ## 46: LL Cool J ## 47: LL Cool J ## 48: LL Cool J ## 49: LL Cool J ## 50: LL Cool J ## 51: LL Cool J ## 52: LL Cool J ## 53: LL Cool J ## 54: LL Cool J ## 55: LL Cool J ## 56: LL Cool J ## 57: LL Cool J ## 58: LL Cool J ## 59: LL Cool J ## 60: LL Cool J ## Psuedonym ## Single ## 1: &quot;I Need a Beat&quot; ## 2: &quot;I Can&#39;t Live Without My Radio&quot; ## 3: &quot;Rock the Bells&quot; ## 4: &quot;I Can Give You More&quot; ## 5: &quot;You&#39;ll Rock&quot; ## 6: &quot;I&#39;m Bad&quot; ## 7: &quot;I Need Love&quot; ## 8: &quot;Go Cut Creator Go&quot; ## 9: &quot;Going Back to Cali&quot; ## 10: &quot;I&#39;m That Type of Guy&quot; ## 11: &quot;Big Ole Butt&quot; ## 12: &quot;One Shot at Love&quot; ## 13: &quot;Jingling Baby&quot; ## 14: &quot;To da Break of Dawn&quot; ## 15: &quot;The Boomin&#39; System&quot; ## 16: &quot;Around the Way Girl&quot; ## 17: &quot;Mama Said Knock You Out&quot; ## 18: &quot;Around the Way Girl&quot; (remix) ## 19: &quot;6 Minutes of Pleasure&quot; ## 20: &quot;Who&#39;s Afraid of the Big Bad Wolf?&quot; ## 21: &quot;Strictly Business&quot; ## 22: &quot;How I&#39;m Comin&#39;&quot; ## 23: &quot;Back Seat (Of My Jeep)&quot; ## 24: &quot;Pink Cookies In a Plastic Bag Getting Crushed by Buildings&quot; ## 25: &quot;Stand By Your Man&quot; ## 26: &quot;Hey Lover&quot; (featuring Boyz II Men) ## 27: &quot;Doin&#39; It&quot; (featuring LeShaun) ## 28: &quot;Loungin&quot; (featuring Total) ## 29: &quot;Ain&#39;t Nobody&quot; ## 30: &quot;Hit &#39;Em High (The Monstars&#39; Anthem)&quot; (with B-Real, Busta Rhymes, Coolio and Method Man) ## 31: &quot;Phenomenon&quot; ## 32: &quot;4, 3, 2, 1&quot; (featuring Method Man, Redman, Canibusand DMX) ## 33: &quot;Father&quot; ## 34: &quot;Hot Hot Hot&quot; ## 35: &quot;Zoom&quot; (with Dr. Dre) ## 36: &quot;Deepest Bluest&quot; ## 37: &quot;Imagine That&quot; ## 38: &quot;Take it Off&quot; ## 39: &quot;You and Me&quot; (featuring Kelly Price) ## 40: &quot;Shut &#39;Em Down&quot; ## 41: &quot;Luv U Better&quot; ## 42: &quot;Paradise&quot; (featuring Ameriie) ## 43: &quot;Amazin&#39;&quot; ## 44: &quot;Headsprung&quot; ## 45: &quot;Hush&quot; (featuring 7 Aurelius) ## 46: &quot;It&#39;s LL and Santana&quot; (featuring Juelz Santana) ## 47: &quot;Control Myself&quot; (featuring Jennifer Lopez) ## 48: &quot;Freeze&quot; (featuring Lyfe Jennings) ## 49: &quot;Cry&quot; (featuring Lil&#39; Mo) ## 50: &quot;Baby&quot; (featuring The-Dream) ## 51: &quot;NCIS: No Crew Is Superior&quot; ## 52: &quot;No More&quot; (featuring Ne-Yo) ## 53: &quot;Ratchet&quot; ## 54: &quot;Take It&quot; (featuring Joe) ## 55: &quot;Whaddup&quot; (featuring Chuck D, Travis Barker, Tom Morello and DJ Z-Trip) ## 56: &quot;We Came to Party&quot; (featuring Snoop Dogg andFatman Scoop) ## 57: &quot;Live for You&quot; (featuring Brad Paisley) ## 58: &quot;Not Leaving You Tonight&quot; (featuring Fitz &amp; The Tantrums with Eddie Van Halen) ## 59: &quot;The Hustler&quot; (featuring Mavado) ## 60: &quot;You Already&quot; (featuring Troy Ave) ## Single ## Top_US_Rap_Chart ## 1: NA ## 2: NA ## 3: NA ## 4: NA ## 5: NA ## 6: NA ## 7: NA ## 8: NA ## 9: NA ## 10: 1 ## 11: 13 ## 12: NA ## 13: 6 ## 14: 17 ## 15: 1 ## 16: 1 ## 17: 1 ## 18: NA ## 19: 7 ## 20: NA ## 21: NA ## 22: 1 ## 23: 2 ## 24: NA ## 25: 24 ## 26: 1 ## 27: 2 ## 28: 1 ## 29: 23 ## 30: NA ## 31: 14 ## 32: 10 ## 33: 1 ## 34: NA ## 35: NA ## 36: NA ## 37: 16 ## 38: 35 ## 39: 44 ## 40: 31 ## 41: 2 ## 42: 10 ## 43: NA ## 44: 4 ## 45: 11 ## 46: NA ## 47: 9 ## 48: NA ## 49: NA ## 50: 10 ## 51: NA ## 52: NA ## 53: NA ## 54: NA ## 55: NA ## 56: NA ## 57: NA ## 58: NA ## 59: NA ## 60: NA ## Top_US_Rap_Chart rap_artist_singles_dt[Psuedonym %like% &quot;LL&quot; &amp; !is.na(Top_US_Rap_Chart), .(Psuedonym, Single, Top_US_Rap_Chart)] ## Psuedonym Single ## 1: LL Cool J &quot;I&#39;m That Type of Guy&quot; ## 2: LL Cool J &quot;Big Ole Butt&quot; ## 3: LL Cool J &quot;Jingling Baby&quot; ## 4: LL Cool J &quot;To da Break of Dawn&quot; ## 5: LL Cool J &quot;The Boomin&#39; System&quot; ## 6: LL Cool J &quot;Around the Way Girl&quot; ## 7: LL Cool J &quot;Mama Said Knock You Out&quot; ## 8: LL Cool J &quot;6 Minutes of Pleasure&quot; ## 9: LL Cool J &quot;How I&#39;m Comin&#39;&quot; ## 10: LL Cool J &quot;Back Seat (Of My Jeep)&quot; ## 11: LL Cool J &quot;Stand By Your Man&quot; ## 12: LL Cool J &quot;Hey Lover&quot; (featuring Boyz II Men) ## 13: LL Cool J &quot;Doin&#39; It&quot; (featuring LeShaun) ## 14: LL Cool J &quot;Loungin&quot; (featuring Total) ## 15: LL Cool J &quot;Ain&#39;t Nobody&quot; ## 16: LL Cool J &quot;Phenomenon&quot; ## 17: LL Cool J &quot;4, 3, 2, 1&quot; (featuring Method Man, Redman, Canibusand DMX) ## 18: LL Cool J &quot;Father&quot; ## 19: LL Cool J &quot;Imagine That&quot; ## 20: LL Cool J &quot;Take it Off&quot; ## 21: LL Cool J &quot;You and Me&quot; (featuring Kelly Price) ## 22: LL Cool J &quot;Shut &#39;Em Down&quot; ## 23: LL Cool J &quot;Luv U Better&quot; ## 24: LL Cool J &quot;Paradise&quot; (featuring Ameriie) ## 25: LL Cool J &quot;Headsprung&quot; ## 26: LL Cool J &quot;Hush&quot; (featuring 7 Aurelius) ## 27: LL Cool J &quot;Control Myself&quot; (featuring Jennifer Lopez) ## 28: LL Cool J &quot;Baby&quot; (featuring The-Dream) ## Psuedonym Single ## Top_US_Rap_Chart ## 1: 1 ## 2: 13 ## 3: 6 ## 4: 17 ## 5: 1 ## 6: 1 ## 7: 1 ## 8: 7 ## 9: 1 ## 10: 2 ## 11: 24 ## 12: 1 ## 13: 2 ## 14: 1 ## 15: 23 ## 16: 14 ## 17: 10 ## 18: 1 ## 19: 16 ## 20: 35 ## 21: 44 ## 22: 31 ## 23: 2 ## 24: 10 ## 25: 4 ## 26: 11 ## 27: 9 ## 28: 10 ## Top_US_Rap_Chart rap_artist_singles_dt[Psuedonym %like% &quot;LL&quot; &amp; !is.na(Top_US_Rap_Chart), .(.N), c(&quot;Psuedonym&quot;, &quot;Top_US_Rap_Chart&quot;)] ## Psuedonym Top_US_Rap_Chart N ## 1: LL Cool J 1 8 ## 2: LL Cool J 13 1 ## 3: LL Cool J 6 1 ## 4: LL Cool J 17 1 ## 5: LL Cool J 7 1 ## 6: LL Cool J 2 3 ## 7: LL Cool J 24 1 ## 8: LL Cool J 23 1 ## 9: LL Cool J 14 1 ## 10: LL Cool J 10 3 ## 11: LL Cool J 16 1 ## 12: LL Cool J 35 1 ## 13: LL Cool J 44 1 ## 14: LL Cool J 31 1 ## 15: LL Cool J 4 1 ## 16: LL Cool J 11 1 ## 17: LL Cool J 9 1 rap_artist_singles_dt[Psuedonym %like% &quot;LL&quot; &amp; !is.na(Top_US_Rap_Chart), .(.N), c(&quot;Psuedonym&quot;, &quot;Top_US_Rap_Chart&quot;)][order(Top_US_Rap_Chart)] ## Psuedonym Top_US_Rap_Chart N ## 1: LL Cool J 1 8 ## 2: LL Cool J 2 3 ## 3: LL Cool J 4 1 ## 4: LL Cool J 6 1 ## 5: LL Cool J 7 1 ## 6: LL Cool J 9 1 ## 7: LL Cool J 10 3 ## 8: LL Cool J 11 1 ## 9: LL Cool J 13 1 ## 10: LL Cool J 14 1 ## 11: LL Cool J 16 1 ## 12: LL Cool J 17 1 ## 13: LL Cool J 23 1 ## 14: LL Cool J 24 1 ## 15: LL Cool J 31 1 ## 16: LL Cool J 35 1 ## 17: LL Cool J 44 1 "],
["vectors.html", "Chapter 11 Vectors", " Chapter 11 Vectors "],
["functions.html", "Chapter 12 Functions", " Chapter 12 Functions "],
["iteration.html", "Chapter 13 Iteration", " Chapter 13 Iteration "],
["r-dialects.html", "Chapter 14 R Dialects", " Chapter 14 R Dialects "],
["spatial-data.html", "Chapter 15 Spatial Data", " Chapter 15 Spatial Data "],
["apis-and-web-scraping.html", "Chapter 16 APIs and Web Scraping", " Chapter 16 APIs and Web Scraping Selector Gadget: http://selectorgadget.com/ DataCamp: https://www.datacamp.com/courses/working-with-web-data-in-r Additional Resources: https://stat4701.github.io/edav/2015/04/02/rvest_tutorial/ "],
["tables-from-websites-wikipedia.html", "16.1 Tables from websites (wikipedia)", " 16.1 Tables from websites (wikipedia) library(RCurl) ## Loading required package: bitops library(XML) wiki_url &lt;- RCurl::getURL(&quot;https://en.wikipedia.org/wiki/List_of_U.S._state_abbreviations&quot;) tables &lt;- XML::readHTMLTable(wiki_url) class(tables) ## [1] &quot;list&quot; length(tables) ## [1] 5 abbrevs &lt;- tables[[1]] head(abbrevs) ## V1 ## 1 Codes: ## 2     ISO ## 3     ANSI ## 4     USPS ## 5     USCG ## 6 Abbreviations: ## V2 ## 1 &lt;NA&gt; ## 2 ISO 3166 codes (2-letter, 3-letter, and 3-digit codes from ISO 3166-1; 2+2-letter codes from ISO 3166-2) ## 3 2-letter and 2-digit codes from the ANSI standard INCITS 38:2009 ## 4 2-letter codes used by the United States Postal Service ## 5 2-letter codes used by the United States Coast Guard (red text shows differences between ANSI and USCG) ## 6 &lt;NA&gt; ## V3 V4 V5 V6 V7 V8 V9 V10 ## 1 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 2 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 3 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 4 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 5 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; ## 6 &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; &lt;NA&gt; us &lt;- abbrevs[11:nrow(abbrevs), ] head(us) ## V1 V2 V3 V4 V5 V6 V7 V8 ## 11  United States of America Federal state US\\nUSA\\n840 US 00 U.S. ## 12  Alabama State US-AL AL 01 AL AL Ala. ## 13  Alaska State US-AK AK 02 AK AK Alaska ## 14  Arizona State US-AZ AZ 04 AZ AZ Ariz. ## 15  Arkansas State US-AR AR 05 AR AR Ark. ## 16  California State US-CA CA 06 CA CF Calif. ## V9 V10 ## 11 U.S. U.S.A. ## 12 Ala. ## 13 Alaska Alas. ## 14 Ariz. Az. ## 15 Ark. ## 16 Calif. Ca., Cal. Write a test to make sure what you got is what you expect first_value &lt;- stringr::str_trim((as.character(us[1, 1]))) testthat::expect_equal(object = first_value, expected = &#39;United States of America&#39;) "],
["websites-rvest.html", "16.2 Websites (rvest)", " 16.2 Websites (rvest) IMDB Top Rated Movies: http://www.imdb.com/chart/top?ref_=nv_mv_250_6 http://selectorgadget.com/ CSS class and id library(rvest) ## Loading required package: xml2 ## ## Attaching package: &#39;rvest&#39; ## The following object is masked from &#39;package:XML&#39;: ## ## xml lego_movie &lt;- read_html(&quot;http://www.imdb.com/title/tt1490017/&quot;) # Rating lego_movie %&gt;% html_node(&quot;strong span&quot;) %&gt;% html_text() %&gt;% as.numeric() ## [1] 7.8 # First page of actors lego_movie %&gt;% html_nodes(&quot;.itemprop .itemprop&quot;) %&gt;% html_text() ## [1] &quot;Will Arnett&quot; &quot;Elizabeth Banks&quot; &quot;Craig Berry&quot; ## [4] &quot;Alison Brie&quot; &quot;David Burrows&quot; &quot;Anthony Daniels&quot; ## [7] &quot;Charlie Day&quot; &quot;Amanda Farinos&quot; &quot;Keith Ferguson&quot; ## [10] &quot;Will Ferrell&quot; &quot;Will Forte&quot; &quot;Dave Franco&quot; ## [13] &quot;Morgan Freeman&quot; &quot;Todd Hansen&quot; &quot;Jonah Hill&quot; lego_movie %&gt;% html_nodes(&quot;table&quot;) %&gt;% .[[1]] %&gt;% html_table() ## X1 X2 ## 1 Cast overview, first billed only: Cast overview, first billed only: ## 2 Will Arnett ## 3 Elizabeth Banks ## 4 Craig Berry ## 5 Alison Brie ## 6 David Burrows ## 7 Anthony Daniels ## 8 Charlie Day ## 9 Amanda Farinos ## 10 Keith Ferguson ## 11 Will Ferrell ## 12 Will Forte ## 13 Dave Franco ## 14 Morgan Freeman ## 15 Todd Hansen ## 16 Jonah Hill ## X3 ## 1 Cast overview, first billed only: ## 2 ... ## 3 ... ## 4 ... ## 5 ... ## 6 ... ## 7 ... ## 8 ... ## 9 ... ## 10 ... ## 11 ... ## 12 ... ## 13 ... ## 14 ... ## 15 ... ## 16 ... ## X4 ## 1 Cast overview, first billed only: ## 2 Batman / \\n Bruce Wayne \\n \\n \\n (voice) ## 3 Wyldstyle / \\n Lucy \\n \\n \\n (voice) ## 4 Blake / \\n Additional Voices \\n \\n \\n (voice) ## 5 Unikitty \\n \\n \\n (voice) ## 6 Octan Robot / \\n Additional Voices \\n \\n \\n (voice) ## 7 C-3PO \\n \\n \\n (voice) ## 8 Benny \\n \\n \\n (voice) ## 9 Mom \\n \\n \\n (voice) ## 10 Han Solo \\n \\n \\n (voice) ## 11 Lord Business / \\n President Business / \\n The Man Upstairs \\n \\n \\n (voice) ## 12 Abraham Lincoln \\n \\n \\n (voice) (as Orville Forte) ## 13 Wally \\n \\n \\n (voice) ## 14 Vitruvius \\n \\n \\n (voice) ## 15 Gandalf / \\n Additional Voices \\n \\n \\n (voice) ## 16 Green Lantern \\n \\n \\n (voice) lego_movie %&gt;% html_nodes(&quot;.primary_photo , .ellipsis, .character, #titleCast .itemprop, #titleCast .loadlate&quot;) ## {xml_nodeset (87)} ## [1] &lt;td class=&quot;primary_photo&quot;&gt;\\n&lt;a href=&quot;/name/nm0004715/?ref_=tt_cl_i1 ... ## [2] &lt;img height=&quot;44&quot; width=&quot;32&quot; alt=&quot;Will Arnett&quot; title=&quot;Will Arnett&quot; s ... ## [3] &lt;td class=&quot;itemprop&quot; itemprop=&quot;actor&quot; itemscope itemtype=&quot;http://sc ... ## [4] &lt;span class=&quot;itemprop&quot; itemprop=&quot;name&quot;&gt;Will Arnett&lt;/span&gt; ## [5] &lt;td class=&quot;ellipsis&quot;&gt;\\n ...\\n &lt;/td&gt; ## [6] &lt;td class=&quot;character&quot;&gt;\\n &lt;a href=&quot;/title/tt1490017/chara ... ## [7] &lt;td class=&quot;primary_photo&quot;&gt;\\n&lt;a href=&quot;/name/nm0006969/?ref_=tt_cl_i2 ... ## [8] &lt;img height=&quot;44&quot; width=&quot;32&quot; alt=&quot;Elizabeth Banks&quot; title=&quot;Elizabeth ... ## [9] &lt;td class=&quot;itemprop&quot; itemprop=&quot;actor&quot; itemscope itemtype=&quot;http://sc ... ## [10] &lt;span class=&quot;itemprop&quot; itemprop=&quot;name&quot;&gt;Elizabeth Banks&lt;/span&gt; ## [11] &lt;td class=&quot;ellipsis&quot;&gt;\\n ...\\n &lt;/td&gt; ## [12] &lt;td class=&quot;character&quot;&gt;\\n &lt;a href=&quot;/title/tt1490017/chara ... ## [13] &lt;td class=&quot;primary_photo&quot;&gt;\\n&lt;a href=&quot;/name/nm1911947/?ref_=tt_cl_i3 ... ## [14] &lt;td class=&quot;itemprop&quot; itemprop=&quot;actor&quot; itemscope itemtype=&quot;http://sc ... ## [15] &lt;span class=&quot;itemprop&quot; itemprop=&quot;name&quot;&gt;Craig Berry&lt;/span&gt; ## [16] &lt;td class=&quot;ellipsis&quot;&gt;\\n ...\\n &lt;/td&gt; ## [17] &lt;td class=&quot;character&quot;&gt;\\n Blake / \\n Addition ... ## [18] &lt;td class=&quot;primary_photo&quot;&gt;\\n&lt;a href=&quot;/name/nm1555340/?ref_=tt_cl_i4 ... ## [19] &lt;img height=&quot;44&quot; width=&quot;32&quot; alt=&quot;Alison Brie&quot; title=&quot;Alison Brie&quot; s ... ## [20] &lt;td class=&quot;itemprop&quot; itemprop=&quot;actor&quot; itemscope itemtype=&quot;http://sc ... ## ... # more manual way lego_movie %&gt;% html_nodes(&quot;table&quot;) %&gt;% .[[1]] %&gt;% html_nodes(&quot;tr&quot;) %&gt;% html_nodes(&quot;span&quot;) %&gt;% html_text() ## [1] &quot;Will Arnett&quot; &quot;Elizabeth Banks&quot; &quot;Craig Berry&quot; ## [4] &quot;Alison Brie&quot; &quot;David Burrows&quot; &quot;Anthony Daniels&quot; ## [7] &quot;Charlie Day&quot; &quot;Amanda Farinos&quot; &quot;Keith Ferguson&quot; ## [10] &quot;Will Ferrell&quot; &quot;Will Forte&quot; &quot;Dave Franco&quot; ## [13] &quot;Morgan Freeman&quot; &quot;Todd Hansen&quot; &quot;Jonah Hill&quot; "],
["selenium.html", "16.3 Selenium", " 16.3 Selenium "],
["communication.html", "Chapter 17 Communication", " Chapter 17 Communication "],
["shiny.html", "Chapter 18 Shiny", " Chapter 18 Shiny "],
["text-mining.html", "Chapter 19 Text Mining", " Chapter 19 Text Mining "],
["git-1.html", "Chapter 20 Git", " Chapter 20 Git Software-Carpentry Git Lesson DataCamp Courses: Introduction to Git for Data Science Working with the RStudio IDE (Part 2) – Chapter 2: Version Control Quick References: Software-Carpentry Reference Git Cheat Sheet (by Github) Jenny Bryan’s “Happy Git and GitHub for the useR” Git interaction from NDP Software Learn Git Branching Git and the “final” version problem If these comics bring back haunting memories, then version control is for you! Technically, renaming copies of files is a form of version control. It allows you to go back to a specific state of a file. As the two comics point out, this usually ends up in a cacophony of files with similar names. What about files and programs that know how to track changes already. I’m mainly thinking about Word documents. "],
["git-on-your-own.html", "20.1 Git on your own", " 20.1 Git on your own Figure 20.1: Diagram of Git commands and how they relate to one another. How not to write commit messages: how #not to write #git #commit messages -.-'' pic.twitter.com/5TdiZ1yi5S — Dⓐniel Chen ((???)) April 16, 2015 "],
["git-with-branches.html", "20.2 Git with branches", " 20.2 Git with branches Figure 20.2: Review of Git Figure 20.3: What branching looks like in the Git world "],
["collaborating-with-git.html", "20.3 Collaborating with Git", " 20.3 Collaborating with Git Figure .: The ‘forking’ model of Git workflows Figure .: Git with branches "],
["protecting-branches.html", "20.4 Protecting branches", " 20.4 Protecting branches https://docs.gitlab.com/ee/user/project/protected_branches.html In a repository go to settings &gt; repository &gt; protected branches set “allowed to merge”: masters “allowed to push”: no one If you accidently did work on master: create a branch where you are now: git branch BRANCH_NAME reset master to where you were: git reset --hard COMMIT_HASH_FOR_MASTER make sure you do this on the master branch go to your branch: git checkout BRANCH_NAME push your branch: git push origin BRANCH_NAME create and merge the pull/merge request "],
["build-details.html", "Build Details", " Build Details Sys.time() ## [1] &quot;2018-06-15 11:57:57 EDT&quot; sessionInfo() ## R version 3.5.0 (2018-04-23) ## Platform: x86_64-pc-linux-gnu (64-bit) ## Running under: Arch Linux ## ## Matrix products: default ## BLAS: /usr/lib/libblasp-r0.3.0.dev.so ## LAPACK: /usr/lib/liblapack.so.3.8.0 ## ## locale: ## [1] LC_CTYPE=en_US.UTF-8 LC_NUMERIC=C ## [3] LC_TIME=en_US.UTF-8 LC_COLLATE=en_US.UTF-8 ## [5] LC_MONETARY=en_US.UTF-8 LC_MESSAGES=en_US.UTF-8 ## [7] LC_PAPER=en_US.UTF-8 LC_NAME=C ## [9] LC_ADDRESS=C LC_TELEPHONE=C ## [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## loaded via a namespace (and not attached): ## [1] compiler_3.5.0 backports_1.1.2 bookdown_0.7 magrittr_1.5 ## [5] rprojroot_1.3-2 tools_3.5.0 htmltools_0.3.6 yaml_2.1.19 ## [9] Rcpp_0.12.17 stringi_1.2.2 rmarkdown_1.9 knitr_1.20 ## [13] xfun_0.1 stringr_1.3.1 digest_0.6.15 evaluate_0.10.1 devtools::session_info() ## Session info ------------------------------------------------------------- ## setting value ## version R version 3.5.0 (2018-04-23) ## system x86_64, linux-gnu ## ui X11 ## language (EN) ## collate en_US.UTF-8 ## tz America/New_York ## date 2018-06-15 ## Packages ----------------------------------------------------------------- ## package * version date source ## backports 1.1.2 2017-12-13 CRAN (R 3.5.0) ## base * 3.5.0 2018-04-23 local ## bookdown 0.7 2018-02-18 CRAN (R 3.5.0) ## compiler 3.5.0 2018-04-23 local ## datasets * 3.5.0 2018-04-23 local ## devtools 1.13.5 2018-02-18 CRAN (R 3.5.0) ## digest 0.6.15 2018-01-28 CRAN (R 3.5.0) ## evaluate 0.10.1 2017-06-24 CRAN (R 3.5.0) ## graphics * 3.5.0 2018-04-23 local ## grDevices * 3.5.0 2018-04-23 local ## htmltools 0.3.6 2017-04-28 CRAN (R 3.5.0) ## knitr 1.20 2018-02-20 CRAN (R 3.5.0) ## magrittr 1.5 2014-11-22 CRAN (R 3.5.0) ## memoise 1.1.0 2017-04-21 CRAN (R 3.5.0) ## methods * 3.5.0 2018-04-23 local ## Rcpp 0.12.17 2018-05-18 CRAN (R 3.5.0) ## rmarkdown 1.9 2018-03-01 CRAN (R 3.5.0) ## rprojroot 1.3-2 2018-01-03 CRAN (R 3.5.0) ## stats * 3.5.0 2018-04-23 local ## stringi 1.2.2 2018-05-02 CRAN (R 3.5.0) ## stringr 1.3.1 2018-05-10 CRAN (R 3.5.0) ## tools 3.5.0 2018-04-23 local ## utils * 3.5.0 2018-04-23 local ## withr 2.1.2 2018-03-15 CRAN (R 3.5.0) ## xfun 0.1 2018-01-22 CRAN (R 3.5.0) ## yaml 2.1.19 2018-05-01 CRAN (R 3.5.0) The all data revolution! "],
["references.html", "References", " References "]
]
